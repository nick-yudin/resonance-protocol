{
  "experiment_info": {
    "name": "Paper 2: Encoder-Free HDC Text Classification",
    "date": "2025-12-22 03:11:36",
    "method": "HyperEmbed (char n-grams \u2192 hash \u2192 ternary HDC)",
    "dimension": 4096,
    "n_runs": 5,
    "max_train": 20000,
    "max_test": 5000,
    "ngrams_tested": [
      3,
      4,
      5,
      6
    ]
  },
  "bert_baselines": {
    "lang_id": {
      "accuracy_measured": 0.994,
      "accuracy_literature": 0.99,
      "model": "papluca/xlm-roberta-base-language-detection",
      "measured_on_same_data": true
    },
    "ag_news": {
      "accuracy_measured": 0.941,
      "accuracy_literature": 0.95,
      "model": "fabriceyhc/bert-base-uncased-ag_news",
      "measured_on_same_data": true
    },
    "sst2": {
      "accuracy_measured": 0.9243119266055045,
      "accuracy_literature": 0.94,
      "model": "textattack/bert-base-uncased-SST-2",
      "measured_on_same_data": true
    }
  },
  "hdc_results": {
    "lang_id": {
      "task": "Language ID",
      "num_classes": 20,
      "best_ngram": 3,
      "best_accuracy": {
        "mean": 0.943,
        "std": 0.002287356552879322,
        "ci_95": 0.0020049564184789607
      },
      "gap_to_bert": 0.051000000000000045,
      "all_ngram_results": {
        "3": {
          "mean": 0.943,
          "std": 0.002287356552879322,
          "ci_95": 0.0020049564184789607,
          "min": 0.9394,
          "max": 0.9464,
          "all_runs": [
            0.943,
            0.9464,
            0.9394,
            0.9422,
            0.944
          ],
          "train_time_mean": 59.19380626678467,
          "test_time_mean": 11.568797492980957
        },
        "4": {
          "mean": 0.8936,
          "std": 0.0020823064135712583,
          "ci_95": 0.0018252220467658163,
          "min": 0.8908,
          "max": 0.896,
          "all_runs": [
            0.8908,
            0.896,
            0.893,
            0.8922,
            0.896
          ],
          "train_time_mean": 109.55627827644348,
          "test_time_mean": 22.173852920532227
        },
        "5": {
          "mean": 0.817,
          "std": 0.0030225816779700177,
          "ci_95": 0.0026494096549986444,
          "min": 0.8136,
          "max": 0.8216,
          "all_runs": [
            0.8186,
            0.8216,
            0.8136,
            0.8138,
            0.8174
          ],
          "train_time_mean": 189.76030945777893,
          "test_time_mean": 37.4636787891388
        },
        "6": {
          "mean": 0.70828,
          "std": 0.003583517824708024,
          "ci_95": 0.0031410918662146924,
          "min": 0.7038,
          "max": 0.7144,
          "all_runs": [
            0.709,
            0.7038,
            0.7144,
            0.7084,
            0.7058
          ],
          "train_time_mean": 279.53068604469297,
          "test_time_mean": 56.58709459304809
        }
      }
    },
    "ag_news": {
      "task": "Topic Classification",
      "num_classes": 4,
      "best_ngram": 6,
      "best_accuracy": {
        "mean": 0.76796,
        "std": 0.001907459042810622,
        "ci_95": 0.001671961568936323
      },
      "gap_to_bert": 0.17303999999999997,
      "all_ngram_results": {
        "3": {
          "mean": 0.7033200000000001,
          "std": 0.004789321455070627,
          "ci_95": 0.004198025349137362,
          "min": 0.6964,
          "max": 0.71,
          "all_runs": [
            0.71,
            0.7058,
            0.6996,
            0.7048,
            0.6964
          ],
          "train_time_mean": 23.240682744979857,
          "test_time_mean": 4.844903469085693
        },
        "4": {
          "mean": 0.7508,
          "std": 0.001901578291840771,
          "ci_95": 0.0016668068634368078,
          "min": 0.7494,
          "max": 0.7542,
          "all_runs": [
            0.7516,
            0.7542,
            0.7494,
            0.7494,
            0.7494
          ],
          "train_time_mean": 48.33224639892578,
          "test_time_mean": 7.036486196517944
        },
        "5": {
          "mean": 0.7612400000000001,
          "std": 0.0005851495535330974,
          "ci_95": 0.0005129061980518339,
          "min": 0.7606,
          "max": 0.7622,
          "all_runs": [
            0.7606,
            0.7616,
            0.7608,
            0.761,
            0.7622
          ],
          "train_time_mean": 100.99553174972534,
          "test_time_mean": 13.304521703720093
        },
        "6": {
          "mean": 0.76796,
          "std": 0.001907459042810622,
          "ci_95": 0.001671961568936323,
          "min": 0.765,
          "max": 0.771,
          "all_runs": [
            0.771,
            0.7676,
            0.7682,
            0.768,
            0.765
          ],
          "train_time_mean": 186.33544359207153,
          "test_time_mean": 25.474166870117188
        }
      }
    },
    "sst2": {
      "task": "Sentiment Analysis",
      "num_classes": 2,
      "best_ngram": 5,
      "best_accuracy": {
        "mean": 0.7071100917431192,
        "std": 0.00856951453773825,
        "ci_95": 0.007511510679897722
      },
      "gap_to_bert": 0.2172018348623853,
      "all_ngram_results": {
        "3": {
          "mean": 0.6561926605504588,
          "std": 0.0049934727195131276,
          "ci_95": 0.004376971822291861,
          "min": 0.6502293577981652,
          "max": 0.6651376146788991,
          "all_runs": [
            0.6651376146788991,
            0.6548165137614679,
            0.6571100917431193,
            0.6536697247706422,
            0.6502293577981652
          ],
          "train_time_mean": 5.539134311676025,
          "test_time_mean": 0.40481228828430177
        },
        "4": {
          "mean": 0.7029816513761469,
          "std": 0.004644141452136823,
          "ci_95": 0.004070769465768189,
          "min": 0.6938073394495413,
          "max": 0.7064220183486238,
          "all_runs": [
            0.7064220183486238,
            0.6938073394495413,
            0.7052752293577982,
            0.7052752293577982,
            0.7041284403669725
          ],
          "train_time_mean": 12.438978576660157,
          "test_time_mean": 0.8273295879364013
        },
        "5": {
          "mean": 0.7071100917431192,
          "std": 0.00856951453773825,
          "ci_95": 0.007511510679897722,
          "min": 0.6903669724770642,
          "max": 0.713302752293578,
          "all_runs": [
            0.7098623853211009,
            0.6903669724770642,
            0.713302752293578,
            0.7087155963302753,
            0.713302752293578
          ],
          "train_time_mean": 25.406079149246217,
          "test_time_mean": 1.7794593811035155
        },
        "6": {
          "mean": 0.6885321100917431,
          "std": 0.008224963796807866,
          "ci_95": 0.007209498639557764,
          "min": 0.6743119266055045,
          "max": 0.698394495412844,
          "all_runs": [
            0.6857798165137615,
            0.6743119266055045,
            0.6938073394495413,
            0.698394495412844,
            0.6903669724770642
          ],
          "train_time_mean": 42.55889391899109,
          "test_time_mean": 4.329672622680664
        }
      }
    }
  }
}