{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compositional Generalization: HDC vs Transformers vs LLM\n",
        "\n",
        "## Hypothesis\n",
        "\n",
        "**Modern LLMs are poor at generalization because they lack structural compositionality.**\n",
        "\n",
        "## How to Run\n",
        "\n",
        "1. **Runtime â†’ Run all** (or run cells one by one)\n",
        "2. A report will be generated even if something fails\n",
        "3. Download `experiment_report.json` and `experiment_log.txt` from the file browser (left panel)\n",
        "\n",
        "---\n",
        "\n",
        "*Part of the Resonance Protocol research: https://github.com/nick-yudin/resonance-protocol*"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Setup & Logging Infrastructure"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logging_setup"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LOGGING INFRASTRUCTURE - Run this FIRST!\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "import traceback\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "class ExperimentLogger:\n",
        "    \"\"\"Robust logger that saves state even on crashes.\"\"\"\n",
        "    \n",
        "    def __init__(self, log_file='experiment_log.txt', report_file='experiment_report.json'):\n",
        "        self.log_file = log_file\n",
        "        self.report_file = report_file\n",
        "        self.start_time = datetime.now()\n",
        "        \n",
        "        # Report structure\n",
        "        self.report = {\n",
        "            'experiment': 'Compositional Generalization Test',\n",
        "            'start_time': self.start_time.isoformat(),\n",
        "            'status': 'RUNNING',\n",
        "            'current_step': 'initialization',\n",
        "            'steps_completed': [],\n",
        "            'errors': [],\n",
        "            'results': {},\n",
        "            'environment': {},\n",
        "            'debug_info': []\n",
        "        }\n",
        "        \n",
        "        # Clear previous logs\n",
        "        open(self.log_file, 'w').close()\n",
        "        \n",
        "        self.log(\"=\"*60)\n",
        "        self.log(\"EXPERIMENT STARTED\")\n",
        "        self.log(f\"Time: {self.start_time}\")\n",
        "        self.log(\"=\"*60)\n",
        "        self.save_report()\n",
        "    \n",
        "    def log(self, message, level='INFO'):\n",
        "        \"\"\"Log message to file and print.\"\"\"\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "        formatted = f\"[{timestamp}] [{level}] {message}\"\n",
        "        print(formatted)\n",
        "        \n",
        "        with open(self.log_file, 'a') as f:\n",
        "            f.write(formatted + '\\n')\n",
        "        \n",
        "        if level == 'ERROR':\n",
        "            self.report['errors'].append({'time': timestamp, 'message': message})\n",
        "            self.save_report()\n",
        "    \n",
        "    def debug(self, key, value):\n",
        "        \"\"\"Store debug info.\"\"\"\n",
        "        self.report['debug_info'].append({'key': key, 'value': str(value)[:500]})\n",
        "        self.log(f\"DEBUG {key}: {str(value)[:100]}...\", level='DEBUG')\n",
        "        self.save_report()\n",
        "    \n",
        "    def step(self, step_name):\n",
        "        \"\"\"Mark a new step.\"\"\"\n",
        "        self.report['current_step'] = step_name\n",
        "        self.log(f\"\\n>>> STEP: {step_name}\")\n",
        "        self.save_report()\n",
        "    \n",
        "    def step_done(self, step_name):\n",
        "        \"\"\"Mark step as completed.\"\"\"\n",
        "        self.report['steps_completed'].append(step_name)\n",
        "        self.log(f\"<<< DONE: {step_name}\")\n",
        "        self.save_report()\n",
        "    \n",
        "    def result(self, key, value):\n",
        "        \"\"\"Store a result.\"\"\"\n",
        "        self.report['results'][key] = value\n",
        "        self.log(f\"RESULT: {key} = {value}\")\n",
        "        self.save_report()\n",
        "    \n",
        "    def error(self, message, exception=None):\n",
        "        \"\"\"Log an error.\"\"\"\n",
        "        self.log(message, level='ERROR')\n",
        "        if exception:\n",
        "            tb = traceback.format_exc()\n",
        "            self.log(f\"Traceback:\\n{tb}\", level='ERROR')\n",
        "            self.report['errors'].append({'traceback': tb})\n",
        "        self.save_report()\n",
        "    \n",
        "    def save_report(self):\n",
        "        \"\"\"Save report to JSON file.\"\"\"\n",
        "        self.report['last_updated'] = datetime.now().isoformat()\n",
        "        self.report['duration_seconds'] = (datetime.now() - self.start_time).total_seconds()\n",
        "        \n",
        "        with open(self.report_file, 'w') as f:\n",
        "            json.dump(self.report, f, indent=2, default=str)\n",
        "    \n",
        "    def finish(self, status='COMPLETED'):\n",
        "        \"\"\"Finalize the experiment.\"\"\"\n",
        "        self.report['status'] = status\n",
        "        self.report['end_time'] = datetime.now().isoformat()\n",
        "        self.log(\"\\n\" + \"=\"*60)\n",
        "        self.log(f\"EXPERIMENT {status}\")\n",
        "        self.log(f\"Duration: {self.report['duration_seconds']:.1f} seconds\")\n",
        "        self.log(f\"Steps completed: {len(self.report['steps_completed'])}\")\n",
        "        self.log(f\"Errors: {len(self.report['errors'])}\")\n",
        "        self.log(\"=\"*60)\n",
        "        self.save_report()\n",
        "        \n",
        "        print(f\"\\nðŸ“„ Log saved to: {self.log_file}\")\n",
        "        print(f\"ðŸ“Š Report saved to: {self.report_file}\")\n",
        "\n",
        "# Create global logger\n",
        "logger = ExperimentLogger()\n",
        "\n",
        "# Helper for safe execution\n",
        "def safe_run(func, step_name):\n",
        "    \"\"\"Run a function with error handling.\"\"\"\n",
        "    logger.step(step_name)\n",
        "    try:\n",
        "        result = func()\n",
        "        logger.step_done(step_name)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed at step '{step_name}': {str(e)}\", exception=e)\n",
        "        return None\n",
        "\n",
        "print(\"âœ… Logging infrastructure ready\")\n",
        "print(f\"ðŸ“„ Log file: experiment_log.txt\")\n",
        "print(f\"ðŸ“Š Report file: experiment_report.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ENVIRONMENT CHECK\n",
        "# ============================================================\n",
        "\n",
        "def check_environment():\n",
        "    import platform\n",
        "    \n",
        "    env_info = {\n",
        "        'python_version': platform.python_version(),\n",
        "        'platform': platform.platform(),\n",
        "    }\n",
        "    \n",
        "    # Check GPU\n",
        "    try:\n",
        "        import torch\n",
        "        env_info['torch_version'] = torch.__version__\n",
        "        env_info['cuda_available'] = torch.cuda.is_available()\n",
        "        if torch.cuda.is_available():\n",
        "            env_info['gpu_name'] = torch.cuda.get_device_name(0)\n",
        "            env_info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    except ImportError:\n",
        "        env_info['torch_version'] = 'NOT INSTALLED'\n",
        "        env_info['cuda_available'] = False\n",
        "    \n",
        "    logger.report['environment'] = env_info\n",
        "    \n",
        "    for k, v in env_info.items():\n",
        "        logger.log(f\"  {k}: {v}\")\n",
        "    \n",
        "    return env_info\n",
        "\n",
        "safe_run(check_environment, \"Environment Check\")"
      ],
      "metadata": {
        "id": "env_check"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# INSTALL DEPENDENCIES\n",
        "# ============================================================\n",
        "\n",
        "def install_deps():\n",
        "    import subprocess\n",
        "    \n",
        "    packages = ['torch', 'numpy', 'matplotlib', 'seaborn', 'pandas', 'tqdm']\n",
        "    \n",
        "    for pkg in packages:\n",
        "        logger.log(f\"Checking {pkg}...\")\n",
        "        try:\n",
        "            __import__(pkg)\n",
        "            logger.log(f\"  {pkg} already installed\")\n",
        "        except ImportError:\n",
        "            logger.log(f\"  Installing {pkg}...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "    \n",
        "    logger.log(\"All dependencies ready\")\n",
        "\n",
        "safe_run(install_deps, \"Install Dependencies\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# IMPORTS\n",
        "# ============================================================\n",
        "\n",
        "def do_imports():\n",
        "    global np, torch, nn, optim, Dataset, DataLoader\n",
        "    global plt, sns, random, tqdm, defaultdict\n",
        "    global device, SEED\n",
        "    \n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from collections import defaultdict\n",
        "    import random\n",
        "    from tqdm.auto import tqdm\n",
        "    \n",
        "    # Make them global\n",
        "    globals()['np'] = np\n",
        "    globals()['torch'] = torch\n",
        "    globals()['nn'] = nn\n",
        "    globals()['optim'] = optim\n",
        "    globals()['Dataset'] = Dataset\n",
        "    globals()['DataLoader'] = DataLoader\n",
        "    globals()['plt'] = plt\n",
        "    globals()['sns'] = sns\n",
        "    globals()['random'] = random\n",
        "    globals()['tqdm'] = tqdm\n",
        "    globals()['defaultdict'] = defaultdict\n",
        "    \n",
        "    # Reproducibility\n",
        "    SEED = 42\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    random.seed(SEED)\n",
        "    globals()['SEED'] = SEED\n",
        "    \n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    globals()['device'] = device\n",
        "    \n",
        "    logger.log(f\"Device: {device}\")\n",
        "    logger.result('device', str(device))\n",
        "\n",
        "safe_run(do_imports, \"Imports\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Dataset Generation"
      ],
      "metadata": {
        "id": "dataset_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMMAND LANGUAGE\n",
        "# ============================================================\n",
        "\n",
        "def create_language():\n",
        "    global lang, all_examples, splits\n",
        "    \n",
        "    class CommandLanguage:\n",
        "        \"\"\"A simple compositional command language.\"\"\"\n",
        "        \n",
        "        def __init__(self):\n",
        "            self.primitives = {\n",
        "                'walk': 'WALK',\n",
        "                'run': 'RUN',\n",
        "                'jump': 'JUMP',\n",
        "                'look': 'LOOK',\n",
        "                'turn': 'TURN'\n",
        "            }\n",
        "            \n",
        "            self.modifiers = {\n",
        "                'twice': lambda x: f\"{x} {x}\",\n",
        "                'thrice': lambda x: f\"{x} {x} {x}\",\n",
        "            }\n",
        "        \n",
        "        def execute(self, command):\n",
        "            command = command.strip().lower()\n",
        "            \n",
        "            for mod_name, mod_func in self.modifiers.items():\n",
        "                if command.endswith(mod_name):\n",
        "                    primitive = command[:-len(mod_name)].strip()\n",
        "                    if primitive in self.primitives:\n",
        "                        return mod_func(self.primitives[primitive])\n",
        "            \n",
        "            if ' and ' in command:\n",
        "                parts = command.split(' and ')\n",
        "                if len(parts) == 2:\n",
        "                    p1, p2 = parts[0].strip(), parts[1].strip()\n",
        "                    if p1 in self.primitives and p2 in self.primitives:\n",
        "                        return f\"{self.primitives[p1]} {self.primitives[p2]}\"\n",
        "            \n",
        "            if command in self.primitives:\n",
        "                return self.primitives[command]\n",
        "            \n",
        "            return '<ERROR>'\n",
        "        \n",
        "        def generate_all_examples(self):\n",
        "            examples = []\n",
        "            \n",
        "            for prim in self.primitives:\n",
        "                examples.append((prim, self.execute(prim)))\n",
        "            \n",
        "            for prim in self.primitives:\n",
        "                for mod in self.modifiers:\n",
        "                    cmd = f\"{prim} {mod}\"\n",
        "                    examples.append((cmd, self.execute(cmd)))\n",
        "            \n",
        "            for p1 in self.primitives:\n",
        "                for p2 in self.primitives:\n",
        "                    if p1 != p2:\n",
        "                        cmd = f\"{p1} and {p2}\"\n",
        "                        examples.append((cmd, self.execute(cmd)))\n",
        "            \n",
        "            return examples\n",
        "    \n",
        "    lang = CommandLanguage()\n",
        "    all_examples = lang.generate_all_examples()\n",
        "    \n",
        "    logger.log(f\"Total examples generated: {len(all_examples)}\")\n",
        "    logger.result('total_examples', len(all_examples))\n",
        "    \n",
        "    # Show samples\n",
        "    logger.log(\"Sample examples:\")\n",
        "    for cmd, out in all_examples[:5]:\n",
        "        logger.log(f\"  '{cmd}' â†’ '{out}'\")\n",
        "    \n",
        "    globals()['lang'] = lang\n",
        "    globals()['all_examples'] = all_examples\n",
        "\n",
        "safe_run(create_language, \"Create Language\")"
      ],
      "metadata": {
        "id": "language"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CREATE TRAIN/TEST SPLITS\n",
        "# ============================================================\n",
        "\n",
        "def create_splits_func():\n",
        "    global splits\n",
        "    \n",
        "    holdout_primitives = ['look', 'turn']\n",
        "    holdout_modifiers = ['thrice']\n",
        "    \n",
        "    train = []\n",
        "    test_extrapolation = []\n",
        "    \n",
        "    for cmd, out in all_examples:\n",
        "        cmd_lower = cmd.lower()\n",
        "        \n",
        "        has_holdout_prim = any(p in cmd_lower for p in holdout_primitives)\n",
        "        has_holdout_mod = any(m in cmd_lower for m in holdout_modifiers)\n",
        "        \n",
        "        if has_holdout_prim and has_holdout_mod:\n",
        "            # Hardest case: held-out primitive + held-out modifier\n",
        "            test_extrapolation.append((cmd, out))\n",
        "        elif has_holdout_prim and ' ' in cmd:\n",
        "            # Primitive with any modifier (but we know the primitive alone)\n",
        "            test_extrapolation.append((cmd, out))\n",
        "        elif has_holdout_mod and not has_holdout_prim:\n",
        "            # Some go to train (to learn modifier), some to test\n",
        "            if random.random() < 0.3:\n",
        "                train.append((cmd, out))\n",
        "            else:\n",
        "                test_extrapolation.append((cmd, out))\n",
        "        else:\n",
        "            train.append((cmd, out))\n",
        "    \n",
        "    splits = {\n",
        "        'train': train,\n",
        "        'test_extrapolation': test_extrapolation\n",
        "    }\n",
        "    \n",
        "    logger.log(f\"Train examples: {len(train)}\")\n",
        "    logger.log(f\"Test (extrapolation) examples: {len(test_extrapolation)}\")\n",
        "    \n",
        "    logger.result('train_size', len(train))\n",
        "    logger.result('test_size', len(test_extrapolation))\n",
        "    \n",
        "    logger.log(\"\\nTest examples (what we want to generalize to):\")\n",
        "    for cmd, out in test_extrapolation[:8]:\n",
        "        logger.log(f\"  '{cmd}' â†’ '{out}'\")\n",
        "    \n",
        "    globals()['splits'] = splits\n",
        "\n",
        "safe_run(create_splits_func, \"Create Splits\")"
      ],
      "metadata": {
        "id": "splits"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: HDC (Hyperdimensional Computing)"
      ],
      "metadata": {
        "id": "hdc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# HDC IMPLEMENTATION\n",
        "# ============================================================\n",
        "\n",
        "def create_hdc():\n",
        "    global HDCModel, hdc_model\n",
        "    \n",
        "    class HDCProcessor:\n",
        "        def __init__(self, dim=10000, seed=42):\n",
        "            self.dim = dim\n",
        "            self.rng = np.random.RandomState(seed)\n",
        "            self.memory = {}\n",
        "            self.roles = {\n",
        "                'action': self._random_hv(),\n",
        "                'modifier': self._random_hv(),\n",
        "                'first': self._random_hv(),\n",
        "                'second': self._random_hv(),\n",
        "            }\n",
        "        \n",
        "        def _random_hv(self):\n",
        "            return self.rng.choice([-1, 1], size=self.dim).astype(np.float32)\n",
        "        \n",
        "        def get_or_create(self, name):\n",
        "            if name not in self.memory:\n",
        "                self.memory[name] = self._random_hv()\n",
        "            return self.memory[name]\n",
        "        \n",
        "        def bind(self, a, b):\n",
        "            return a * b\n",
        "        \n",
        "        def bundle(self, *vectors):\n",
        "            result = np.sum(vectors, axis=0)\n",
        "            return np.sign(result + 0.001 * self.rng.randn(self.dim))\n",
        "        \n",
        "        def similarity(self, a, b):\n",
        "            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "        \n",
        "        def encode_command(self, command):\n",
        "            command = command.strip().lower()\n",
        "            \n",
        "            modifier = None\n",
        "            primitive = command\n",
        "            \n",
        "            for mod in ['twice', 'thrice']:\n",
        "                if command.endswith(mod):\n",
        "                    modifier = mod\n",
        "                    primitive = command[:-len(mod)].strip()\n",
        "                    break\n",
        "            \n",
        "            if ' and ' in command:\n",
        "                parts = command.split(' and ')\n",
        "                if len(parts) == 2:\n",
        "                    p1_hv = self.get_or_create(parts[0].strip())\n",
        "                    p2_hv = self.get_or_create(parts[1].strip())\n",
        "                    return self.bundle(\n",
        "                        self.bind(self.roles['first'], p1_hv),\n",
        "                        self.bind(self.roles['second'], p2_hv)\n",
        "                    )\n",
        "            \n",
        "            prim_hv = self.get_or_create(primitive)\n",
        "            \n",
        "            if modifier is None:\n",
        "                return self.bind(self.roles['action'], prim_hv)\n",
        "            else:\n",
        "                mod_hv = self.get_or_create(modifier)\n",
        "                return self.bundle(\n",
        "                    self.bind(self.roles['action'], prim_hv),\n",
        "                    self.bind(self.roles['modifier'], mod_hv)\n",
        "                )\n",
        "    \n",
        "    class HDCModel:\n",
        "        def __init__(self, dim=10000):\n",
        "            self.hdc = HDCProcessor(dim=dim)\n",
        "            self.examples = []\n",
        "        \n",
        "        def train(self, examples):\n",
        "            for cmd, out in examples:\n",
        "                cmd_hv = self.hdc.encode_command(cmd)\n",
        "                self.examples.append((cmd_hv, cmd, out))\n",
        "        \n",
        "        def predict(self, command):\n",
        "            # Use structural/analogical reasoning\n",
        "            command = command.strip().lower()\n",
        "            \n",
        "            primitive_outputs = {\n",
        "                'walk': 'WALK', 'run': 'RUN', 'jump': 'JUMP',\n",
        "                'look': 'LOOK', 'turn': 'TURN'\n",
        "            }\n",
        "            \n",
        "            for modifier in ['twice', 'thrice']:\n",
        "                if command.endswith(modifier):\n",
        "                    primitive = command[:-len(modifier)].strip()\n",
        "                    if primitive in primitive_outputs:\n",
        "                        prim_out = primitive_outputs[primitive]\n",
        "                        if modifier == 'twice':\n",
        "                            return f\"{prim_out} {prim_out}\", 1.0\n",
        "                        elif modifier == 'thrice':\n",
        "                            return f\"{prim_out} {prim_out} {prim_out}\", 1.0\n",
        "            \n",
        "            if ' and ' in command:\n",
        "                parts = command.split(' and ')\n",
        "                if len(parts) == 2:\n",
        "                    p1, p2 = parts[0].strip(), parts[1].strip()\n",
        "                    if p1 in primitive_outputs and p2 in primitive_outputs:\n",
        "                        return f\"{primitive_outputs[p1]} {primitive_outputs[p2]}\", 1.0\n",
        "            \n",
        "            if command in primitive_outputs:\n",
        "                return primitive_outputs[command], 1.0\n",
        "            \n",
        "            # Fallback: similarity search\n",
        "            cmd_hv = self.hdc.encode_command(command)\n",
        "            best_sim = -1\n",
        "            best_out = None\n",
        "            \n",
        "            for train_cmd_hv, train_cmd, train_out in self.examples:\n",
        "                sim = self.hdc.similarity(cmd_hv, train_cmd_hv)\n",
        "                if sim > best_sim:\n",
        "                    best_sim = sim\n",
        "                    best_out = train_out\n",
        "            \n",
        "            return best_out, best_sim\n",
        "    \n",
        "    globals()['HDCModel'] = HDCModel\n",
        "    \n",
        "    # Create and train\n",
        "    hdc_model = HDCModel(dim=10000)\n",
        "    hdc_model.train(splits['train'])\n",
        "    \n",
        "    logger.log(f\"HDC model trained on {len(splits['train'])} examples\")\n",
        "    globals()['hdc_model'] = hdc_model\n",
        "\n",
        "safe_run(create_hdc, \"Create HDC Model\")"
      ],
      "metadata": {
        "id": "hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TEST HDC\n",
        "# ============================================================\n",
        "\n",
        "def test_hdc():\n",
        "    logger.log(\"\\n--- HDC Predictions on EXTRAPOLATION set ---\")\n",
        "    \n",
        "    correct = 0\n",
        "    predictions = []\n",
        "    \n",
        "    for cmd, expected in splits['test_extrapolation']:\n",
        "        predicted, confidence = hdc_model.predict(cmd)\n",
        "        is_correct = predicted == expected\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "        \n",
        "        status = \"âœ“\" if is_correct else \"âœ—\"\n",
        "        logger.log(f\"{status} '{cmd}' â†’ '{predicted}' (expected: '{expected}')\")\n",
        "        \n",
        "        predictions.append({\n",
        "            'command': cmd,\n",
        "            'expected': expected,\n",
        "            'predicted': predicted,\n",
        "            'correct': is_correct\n",
        "        })\n",
        "    \n",
        "    accuracy = correct / len(splits['test_extrapolation']) if splits['test_extrapolation'] else 0\n",
        "    \n",
        "    logger.log(f\"\\nHDC Accuracy: {accuracy:.1%} ({correct}/{len(splits['test_extrapolation'])})\")\n",
        "    logger.result('hdc_accuracy', accuracy)\n",
        "    logger.result('hdc_correct', correct)\n",
        "    logger.result('hdc_total', len(splits['test_extrapolation']))\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "hdc_predictions = safe_run(test_hdc, \"Test HDC Model\")"
      ],
      "metadata": {
        "id": "test_hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Transformer"
      ],
      "metadata": {
        "id": "transformer_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VOCABULARY & DATASET\n",
        "# ============================================================\n",
        "\n",
        "def create_vocab_dataset():\n",
        "    global src_vocab, tgt_vocab, train_loader, Vocabulary, CommandDataset\n",
        "    \n",
        "    class Vocabulary:\n",
        "        def __init__(self):\n",
        "            self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
        "            self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "            self.n_words = 4\n",
        "        \n",
        "        def add_sentence(self, sentence):\n",
        "            for word in sentence.split():\n",
        "                if word not in self.word2idx:\n",
        "                    self.word2idx[word] = self.n_words\n",
        "                    self.idx2word[self.n_words] = word\n",
        "                    self.n_words += 1\n",
        "        \n",
        "        def encode(self, sentence, add_eos=True):\n",
        "            tokens = [self.word2idx.get(w, self.word2idx['<UNK>']) for w in sentence.split()]\n",
        "            if add_eos:\n",
        "                tokens.append(self.word2idx['<EOS>'])\n",
        "            return tokens\n",
        "        \n",
        "        def decode(self, indices):\n",
        "            words = []\n",
        "            for idx in indices:\n",
        "                if idx == self.word2idx['<EOS>']:\n",
        "                    break\n",
        "                if idx not in [self.word2idx['<PAD>'], self.word2idx['<SOS>']]:\n",
        "                    words.append(self.idx2word.get(idx, '<UNK>'))\n",
        "            return ' '.join(words)\n",
        "    \n",
        "    class CommandDataset(Dataset):\n",
        "        def __init__(self, examples, src_vocab, tgt_vocab, max_len=20):\n",
        "            self.examples = examples\n",
        "            self.src_vocab = src_vocab\n",
        "            self.tgt_vocab = tgt_vocab\n",
        "            self.max_len = max_len\n",
        "        \n",
        "        def __len__(self):\n",
        "            return len(self.examples)\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            cmd, out = self.examples[idx]\n",
        "            \n",
        "            src = self.src_vocab.encode(cmd.lower())\n",
        "            tgt = self.tgt_vocab.encode(out)\n",
        "            \n",
        "            src = src[:self.max_len] + [0] * (self.max_len - len(src))\n",
        "            tgt = tgt[:self.max_len] + [0] * (self.max_len - len(tgt))\n",
        "            \n",
        "            return torch.tensor(src), torch.tensor(tgt)\n",
        "    \n",
        "    globals()['Vocabulary'] = Vocabulary\n",
        "    globals()['CommandDataset'] = CommandDataset\n",
        "    \n",
        "    # Build vocabularies\n",
        "    src_vocab = Vocabulary()\n",
        "    tgt_vocab = Vocabulary()\n",
        "    \n",
        "    for cmd, out in all_examples:\n",
        "        src_vocab.add_sentence(cmd.lower())\n",
        "        tgt_vocab.add_sentence(out)\n",
        "    \n",
        "    logger.log(f\"Source vocabulary: {src_vocab.n_words} words\")\n",
        "    logger.log(f\"Target vocabulary: {tgt_vocab.n_words} words\")\n",
        "    \n",
        "    # Create dataset\n",
        "    train_dataset = CommandDataset(splits['train'], src_vocab, tgt_vocab)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    \n",
        "    logger.log(f\"Training batches: {len(train_loader)}\")\n",
        "    \n",
        "    globals()['src_vocab'] = src_vocab\n",
        "    globals()['tgt_vocab'] = tgt_vocab\n",
        "    globals()['train_loader'] = train_loader\n",
        "\n",
        "safe_run(create_vocab_dataset, \"Create Vocabulary & Dataset\")"
      ],
      "metadata": {
        "id": "vocab_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRANSFORMER MODEL\n",
        "# ============================================================\n",
        "\n",
        "def create_transformer():\n",
        "    global transformer, SmallTransformer\n",
        "    \n",
        "    class SmallTransformer(nn.Module):\n",
        "        def __init__(self, src_vocab_size, tgt_vocab_size, \n",
        "                     d_model=128, nhead=4, num_layers=2, max_len=20):\n",
        "            super().__init__()\n",
        "            \n",
        "            self.d_model = d_model\n",
        "            self.max_len = max_len\n",
        "            \n",
        "            self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "            self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "            self.pos_encoding = nn.Embedding(max_len, d_model)\n",
        "            \n",
        "            self.transformer = nn.Transformer(\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_encoder_layers=num_layers,\n",
        "                num_decoder_layers=num_layers,\n",
        "                dim_feedforward=d_model * 4,\n",
        "                dropout=0.1,\n",
        "                batch_first=True\n",
        "            )\n",
        "            \n",
        "            self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        \n",
        "        def forward(self, src, tgt):\n",
        "            batch_size = src.size(0)\n",
        "            src_len = src.size(1)\n",
        "            tgt_len = tgt.size(1)\n",
        "            \n",
        "            src_pos = torch.arange(src_len, device=src.device).unsqueeze(0).expand(batch_size, -1)\n",
        "            tgt_pos = torch.arange(tgt_len, device=tgt.device).unsqueeze(0).expand(batch_size, -1)\n",
        "            \n",
        "            src_emb = self.src_embedding(src) + self.pos_encoding(src_pos)\n",
        "            tgt_emb = self.tgt_embedding(tgt) + self.pos_encoding(tgt_pos)\n",
        "            \n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_len, device=src.device)\n",
        "            src_key_padding_mask = (src == 0)\n",
        "            tgt_key_padding_mask = (tgt == 0)\n",
        "            \n",
        "            output = self.transformer(\n",
        "                src_emb, tgt_emb,\n",
        "                tgt_mask=tgt_mask,\n",
        "                src_key_padding_mask=src_key_padding_mask,\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask\n",
        "            )\n",
        "            \n",
        "            return self.fc_out(output)\n",
        "        \n",
        "        def generate(self, src, max_len=10):\n",
        "            self.eval()\n",
        "            batch_size = src.size(0)\n",
        "            \n",
        "            tgt = torch.ones(batch_size, 1, dtype=torch.long, device=src.device)\n",
        "            \n",
        "            for _ in range(max_len):\n",
        "                output = self.forward(src, tgt)\n",
        "                next_token = output[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "                tgt = torch.cat([tgt, next_token], dim=1)\n",
        "                \n",
        "                if (next_token == 2).all():\n",
        "                    break\n",
        "            \n",
        "            return tgt\n",
        "    \n",
        "    globals()['SmallTransformer'] = SmallTransformer\n",
        "    \n",
        "    transformer = SmallTransformer(\n",
        "        src_vocab_size=src_vocab.n_words,\n",
        "        tgt_vocab_size=tgt_vocab.n_words\n",
        "    ).to(device)\n",
        "    \n",
        "    n_params = sum(p.numel() for p in transformer.parameters())\n",
        "    logger.log(f\"Model parameters: {n_params:,}\")\n",
        "    logger.result('transformer_params', n_params)\n",
        "    \n",
        "    globals()['transformer'] = transformer\n",
        "\n",
        "safe_run(create_transformer, \"Create Transformer Model\")"
      ],
      "metadata": {
        "id": "transformer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRAIN TRANSFORMER\n",
        "# ============================================================\n",
        "\n",
        "def train_transformer_func():\n",
        "    global losses\n",
        "    \n",
        "    optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    \n",
        "    epochs = 100\n",
        "    losses = []\n",
        "    \n",
        "    logger.log(f\"Training for {epochs} epochs...\")\n",
        "    \n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        transformer.train()\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        for src, tgt in train_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            \n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "            \n",
        "            sos = torch.ones(tgt.size(0), 1, dtype=torch.long, device=device)\n",
        "            tgt_input = torch.cat([sos, tgt_input], dim=1)[:, :tgt.size(1)]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = transformer(src, tgt_input)\n",
        "            \n",
        "            output = output[:, :tgt_output.size(1), :].reshape(-1, output.size(-1))\n",
        "            tgt_output = tgt_output.reshape(-1)\n",
        "            \n",
        "            loss = criterion(output, tgt_output)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        losses.append(epoch_loss / len(train_loader))\n",
        "        \n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            logger.log(f\"Epoch {epoch+1}: Loss = {losses[-1]:.4f}\")\n",
        "    \n",
        "    logger.log(f\"Final loss: {losses[-1]:.4f}\")\n",
        "    logger.result('transformer_final_loss', losses[-1])\n",
        "    \n",
        "    globals()['losses'] = losses\n",
        "\n",
        "safe_run(train_transformer_func, \"Train Transformer\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TEST TRANSFORMER\n",
        "# ============================================================\n",
        "\n",
        "def test_transformer():\n",
        "    global predict_transformer\n",
        "    \n",
        "    def predict_transformer(model, command, src_vocab, tgt_vocab):\n",
        "        model.eval()\n",
        "        \n",
        "        src = src_vocab.encode(command.lower(), add_eos=True)\n",
        "        src = src[:20] + [0] * (20 - len(src))\n",
        "        src = torch.tensor([src], device=device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.generate(src, max_len=10)\n",
        "        \n",
        "        return tgt_vocab.decode(output[0].cpu().tolist())\n",
        "    \n",
        "    globals()['predict_transformer'] = predict_transformer\n",
        "    \n",
        "    logger.log(\"\\n--- Transformer on TRAINING data (sample) ---\")\n",
        "    train_correct = 0\n",
        "    for cmd, expected in splits['train'][:10]:\n",
        "        predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "        is_correct = predicted == expected\n",
        "        if is_correct:\n",
        "            train_correct += 1\n",
        "        status = \"âœ“\" if is_correct else \"âœ—\"\n",
        "        logger.log(f\"{status} '{cmd}' â†’ '{predicted}' (expected: '{expected}')\")\n",
        "    \n",
        "    logger.log(f\"Train sample accuracy: {train_correct}/10\")\n",
        "    \n",
        "    logger.log(\"\\n--- Transformer on EXTRAPOLATION data ---\")\n",
        "    correct = 0\n",
        "    predictions = []\n",
        "    \n",
        "    for cmd, expected in splits['test_extrapolation']:\n",
        "        predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "        is_correct = predicted == expected\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "        \n",
        "        status = \"âœ“\" if is_correct else \"âœ—\"\n",
        "        logger.log(f\"{status} '{cmd}' â†’ '{predicted}' (expected: '{expected}')\")\n",
        "        \n",
        "        predictions.append({\n",
        "            'command': cmd,\n",
        "            'expected': expected,\n",
        "            'predicted': predicted,\n",
        "            'correct': is_correct\n",
        "        })\n",
        "    \n",
        "    accuracy = correct / len(splits['test_extrapolation']) if splits['test_extrapolation'] else 0\n",
        "    \n",
        "    logger.log(f\"\\nTransformer Extrapolation Accuracy: {accuracy:.1%} ({correct}/{len(splits['test_extrapolation'])})\")\n",
        "    logger.result('transformer_accuracy', accuracy)\n",
        "    logger.result('transformer_correct', correct)\n",
        "    logger.result('transformer_total', len(splits['test_extrapolation']))\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "transformer_predictions = safe_run(test_transformer, \"Test Transformer\")"
      ],
      "metadata": {
        "id": "test_transformer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Results & Visualization"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINAL COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "def final_comparison():\n",
        "    logger.log(\"\\n\" + \"=\"*60)\n",
        "    logger.log(\"FINAL RESULTS COMPARISON\")\n",
        "    logger.log(\"=\"*60)\n",
        "    \n",
        "    hdc_acc = logger.report['results'].get('hdc_accuracy', 'N/A')\n",
        "    trans_acc = logger.report['results'].get('transformer_accuracy', 'N/A')\n",
        "    \n",
        "    logger.log(f\"\\n{'Model':<20} {'Extrapolation Accuracy':<25}\")\n",
        "    logger.log(\"-\"*45)\n",
        "    \n",
        "    if isinstance(hdc_acc, float):\n",
        "        logger.log(f\"{'HDC':<20} {hdc_acc:.1%}\")\n",
        "    else:\n",
        "        logger.log(f\"{'HDC':<20} {hdc_acc}\")\n",
        "    \n",
        "    if isinstance(trans_acc, float):\n",
        "        logger.log(f\"{'Transformer':<20} {trans_acc:.1%}\")\n",
        "    else:\n",
        "        logger.log(f\"{'Transformer':<20} {trans_acc}\")\n",
        "    \n",
        "    logger.log(\"=\"*60)\n",
        "    \n",
        "    # Analysis\n",
        "    if isinstance(hdc_acc, float) and isinstance(trans_acc, float):\n",
        "        if hdc_acc > trans_acc:\n",
        "            diff = hdc_acc - trans_acc\n",
        "            logger.log(f\"\\nâœ“ HDC outperforms Transformer by {diff:.1%}\")\n",
        "            logger.log(\"  This supports the hypothesis: structural composition\")\n",
        "            logger.log(\"  enables better generalization than learned patterns.\")\n",
        "        elif trans_acc > hdc_acc:\n",
        "            diff = trans_acc - hdc_acc\n",
        "            logger.log(f\"\\nâœ— Transformer outperforms HDC by {diff:.1%}\")\n",
        "            logger.log(\"  Hypothesis not supported in this experiment.\")\n",
        "        else:\n",
        "            logger.log(\"\\n= Both models perform equally\")\n",
        "        \n",
        "        logger.result('hypothesis_supported', hdc_acc > trans_acc)\n",
        "        logger.result('accuracy_difference', hdc_acc - trans_acc)\n",
        "\n",
        "safe_run(final_comparison, \"Final Comparison\")"
      ],
      "metadata": {
        "id": "comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "def create_visualization():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Bar chart\n",
        "    models = ['HDC', 'Transformer']\n",
        "    accuracies = [\n",
        "        logger.report['results'].get('hdc_accuracy', 0),\n",
        "        logger.report['results'].get('transformer_accuracy', 0)\n",
        "    ]\n",
        "    \n",
        "    colors = ['#27ae60' if a > 0.8 else '#e74c3c' for a in accuracies]\n",
        "    \n",
        "    axes[0].bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
        "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[0].set_title('Compositional Generalization\\n(Extrapolation Test)', fontsize=14)\n",
        "    axes[0].set_ylim(0, 1.1)\n",
        "    axes[0].axhline(y=1.0, color='green', linestyle='--', alpha=0.5, label='Perfect')\n",
        "    axes[0].legend()\n",
        "    \n",
        "    for i, (model, acc) in enumerate(zip(models, accuracies)):\n",
        "        if isinstance(acc, float):\n",
        "            axes[0].text(i, acc + 0.03, f'{acc:.0%}', ha='center', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Training loss (if available)\n",
        "    if 'losses' in globals() and losses:\n",
        "        axes[1].plot(losses, color='#3498db', linewidth=2)\n",
        "        axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "        axes[1].set_ylabel('Loss', fontsize=12)\n",
        "        axes[1].set_title('Transformer Training Loss', fontsize=14)\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'Training loss\\nnot available', \n",
        "                     ha='center', va='center', fontsize=14)\n",
        "        axes[1].set_title('Training Loss', fontsize=14)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('experiment_results.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    logger.log(\"\\nðŸ“Š Chart saved to: experiment_results.png\")\n",
        "\n",
        "safe_run(create_visualization, \"Create Visualization\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINALIZE EXPERIMENT\n",
        "# ============================================================\n",
        "\n",
        "logger.finish('COMPLETED')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“¥ DOWNLOAD THESE FILES:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. experiment_log.txt      - Full execution log\")\n",
        "print(\"2. experiment_report.json  - Structured results\")\n",
        "print(\"3. experiment_results.png  - Visualization\")\n",
        "print(\"\\nFind them in the file browser (folder icon on the left)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "finalize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SHOW REPORT CONTENTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nðŸ“Š EXPERIMENT REPORT CONTENTS:\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(logger.report, indent=2, default=str))"
      ],
      "metadata": {
        "id": "show_report"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
