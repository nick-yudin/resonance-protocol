{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üî¨ Fair Compositional Generalization Test v3\n",
        "\n",
        "## Changes from v2\n",
        "\n",
        "- **More training data** (~90% of examples)\n",
        "- **Minimal holdout** (1 primitive, 1 modifier)\n",
        "- **Train accuracy check** before testing extrapolation\n",
        "- **Longer training** until convergence\n",
        "- **Proper evaluation** with verbose output\n",
        "\n",
        "## Fair Test Design\n",
        "\n",
        "- Transformer gets enough data to actually learn\n",
        "- We verify it learned (train acc > 90%) before testing generalization\n",
        "- HDC still uses structural composition\n",
        "\n",
        "---\n",
        "\n",
        "*Resonance Protocol Research*"
      ],
      "metadata": {"id": "intro"}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "setup"},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Results storage\n",
        "RESULTS = {\n",
        "    'start_time': datetime.now().isoformat(),\n",
        "    'device': str(device),\n",
        "    'levels': {},\n",
        "    'summary': {}\n",
        "}\n",
        "\n",
        "def log(msg):\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Language & Data"
      ],
      "metadata": {"id": "data_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMMAND LANGUAGE\n",
        "# ============================================================\n",
        "\n",
        "class CommandLanguage:\n",
        "    def __init__(self):\n",
        "        self.primitives = {\n",
        "            'walk': 'WALK', 'run': 'RUN', 'jump': 'JUMP',\n",
        "            'look': 'LOOK', 'turn': 'TURN', 'spin': 'SPIN',\n",
        "            'crawl': 'CRAWL', 'swim': 'SWIM',\n",
        "        }\n",
        "        \n",
        "        self.modifiers = {\n",
        "            'twice': 2,\n",
        "            'thrice': 3,\n",
        "            'four times': 4,\n",
        "        }\n",
        "    \n",
        "    def execute(self, command):\n",
        "        command = command.strip().lower()\n",
        "        \n",
        "        if ' and ' in command:\n",
        "            parts = command.split(' and ')\n",
        "            if len(parts) == 2:\n",
        "                left = self._execute_single(parts[0].strip())\n",
        "                right = self._execute_single(parts[1].strip())\n",
        "                if left and right:\n",
        "                    return f\"{left} {right}\"\n",
        "        \n",
        "        result = self._execute_single(command)\n",
        "        return result if result else '<e>'\n",
        "    \n",
        "    def _execute_single(self, cmd):\n",
        "        repeat = 1\n",
        "        for mod_name, mod_count in self.modifiers.items():\n",
        "            if cmd.endswith(' ' + mod_name):\n",
        "                repeat = mod_count\n",
        "                cmd = cmd[:-len(mod_name)-1].strip()\n",
        "                break\n",
        "        \n",
        "        if cmd in self.primitives:\n",
        "            return ' '.join([self.primitives[cmd]] * repeat)\n",
        "        return None\n",
        "    \n",
        "    def generate_all(self):\n",
        "        \"\"\"Generate all examples for levels 1-3.\"\"\"\n",
        "        examples = []\n",
        "        \n",
        "        # Level 1: primitives\n",
        "        for p in self.primitives:\n",
        "            examples.append((p, self.execute(p), 1))\n",
        "        \n",
        "        # Level 2: primitive + modifier\n",
        "        for p in self.primitives:\n",
        "            for m in self.modifiers:\n",
        "                cmd = f\"{p} {m}\"\n",
        "                examples.append((cmd, self.execute(cmd), 2))\n",
        "        \n",
        "        # Level 3: primitive and primitive\n",
        "        for p1 in self.primitives:\n",
        "            for p2 in self.primitives:\n",
        "                cmd = f\"{p1} and {p2}\"\n",
        "                examples.append((cmd, self.execute(cmd), 3))\n",
        "        \n",
        "        return examples\n",
        "\n",
        "lang = CommandLanguage()\n",
        "all_examples = lang.generate_all()\n",
        "\n",
        "log(f\"Total examples: {len(all_examples)}\")\n",
        "log(f\"Primitives: {list(lang.primitives.keys())}\")\n",
        "log(f\"Modifiers: {list(lang.modifiers.keys())}\")\n",
        "\n",
        "# Show distribution\n",
        "level_counts = {}\n",
        "for _, _, level in all_examples:\n",
        "    level_counts[level] = level_counts.get(level, 0) + 1\n",
        "log(f\"By level: {level_counts}\")"
      ],
      "metadata": {"id": "language"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MINIMAL HOLDOUT SPLIT\n",
        "# ============================================================\n",
        "\n",
        "# Holdout: only ONE primitive and ONE modifier\n",
        "HOLDOUT_PRIMITIVE = 'swim'  # Only 1 of 8\n",
        "HOLDOUT_MODIFIER = 'four times'  # Only 1 of 3\n",
        "\n",
        "train_data = []\n",
        "test_extrapolation = []\n",
        "\n",
        "for cmd, out, level in all_examples:\n",
        "    has_holdout_prim = HOLDOUT_PRIMITIVE in cmd.lower()\n",
        "    has_holdout_mod = HOLDOUT_MODIFIER in cmd.lower()\n",
        "    \n",
        "    # Put primitive alone in train (so model knows SWIM ‚Üí SWIM)\n",
        "    if cmd.lower() == HOLDOUT_PRIMITIVE:\n",
        "        train_data.append((cmd, out, level))\n",
        "    # Put modifier with ONE primitive in train (so model knows \"four times\" = repeat 4x)\n",
        "    elif has_holdout_mod and 'walk' in cmd.lower() and 'and' not in cmd.lower():\n",
        "        train_data.append((cmd, out, level))\n",
        "    # Extrapolation: combinations with holdout elements\n",
        "    elif has_holdout_prim or has_holdout_mod:\n",
        "        test_extrapolation.append((cmd, out, level))\n",
        "    # Regular training\n",
        "    else:\n",
        "        train_data.append((cmd, out, level))\n",
        "\n",
        "log(f\"\\nSplit:\")\n",
        "log(f\"  Train: {len(train_data)} examples\")\n",
        "log(f\"  Test (extrapolation): {len(test_extrapolation)} examples\")\n",
        "log(f\"  Train ratio: {len(train_data)/len(all_examples):.1%}\")\n",
        "\n",
        "# Show what's in train vs test\n",
        "log(f\"\\nTraining includes:\")\n",
        "train_with_holdout = [e for e in train_data if HOLDOUT_PRIMITIVE in e[0] or HOLDOUT_MODIFIER in e[0]]\n",
        "for cmd, out, _ in train_with_holdout:\n",
        "    log(f\"  '{cmd}' ‚Üí '{out}'\")\n",
        "\n",
        "log(f\"\\nTest extrapolation examples (sample):\")\n",
        "for cmd, out, _ in test_extrapolation[:8]:\n",
        "    log(f\"  '{cmd}' ‚Üí '{out}'\")"
      ],
      "metadata": {"id": "splits"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Vocabulary & Dataset"
      ],
      "metadata": {"id": "vocab_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VOCABULARY\n",
        "# ============================================================\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>'}\n",
        "        self.n_words = 3\n",
        "    \n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.n_words\n",
        "            self.idx2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "    \n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "    \n",
        "    def encode(self, sentence, add_sos=False, add_eos=True):\n",
        "        tokens = []\n",
        "        if add_sos:\n",
        "            tokens.append(self.word2idx['<SOS>'])\n",
        "        for word in sentence.split():\n",
        "            tokens.append(self.word2idx.get(word, 0))\n",
        "        if add_eos:\n",
        "            tokens.append(self.word2idx['<EOS>'])\n",
        "        return tokens\n",
        "    \n",
        "    def decode(self, indices):\n",
        "        words = []\n",
        "        for idx in indices:\n",
        "            if isinstance(idx, torch.Tensor):\n",
        "                idx = idx.item()\n",
        "            if idx == self.word2idx['<EOS>']:\n",
        "                break\n",
        "            word = self.idx2word.get(idx, '')\n",
        "            if word and word not in ['<PAD>', '<SOS>', '<EOS>']:\n",
        "                words.append(word)\n",
        "        return ' '.join(words)\n",
        "\n",
        "# Build from ALL examples (so vocab is complete)\n",
        "src_vocab = Vocabulary()\n",
        "tgt_vocab = Vocabulary()\n",
        "\n",
        "for cmd, out, _ in all_examples:\n",
        "    src_vocab.add_sentence(cmd.lower())\n",
        "    tgt_vocab.add_sentence(out)\n",
        "\n",
        "log(f\"Source vocab: {src_vocab.n_words} tokens\")\n",
        "log(f\"Target vocab: {tgt_vocab.n_words} tokens\")\n",
        "log(f\"Target tokens: {list(tgt_vocab.word2idx.keys())}\")"
      ],
      "metadata": {"id": "vocab"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "\n",
        "class CommandDataset(Dataset):\n",
        "    def __init__(self, examples, src_vocab, tgt_vocab, max_src_len=12, max_tgt_len=10):\n",
        "        self.examples = [(cmd, out) for cmd, out, _ in examples]\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.max_src_len = max_src_len\n",
        "        self.max_tgt_len = max_tgt_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        cmd, out = self.examples[idx]\n",
        "        \n",
        "        src = self.src_vocab.encode(cmd.lower(), add_sos=False, add_eos=True)\n",
        "        tgt = self.tgt_vocab.encode(out, add_sos=True, add_eos=True)\n",
        "        \n",
        "        # Pad\n",
        "        src = src[:self.max_src_len] + [0] * max(0, self.max_src_len - len(src))\n",
        "        tgt = tgt[:self.max_tgt_len] + [0] * max(0, self.max_tgt_len - len(tgt))\n",
        "        \n",
        "        return torch.tensor(src), torch.tensor(tgt)\n",
        "\n",
        "train_dataset = CommandDataset(train_data, src_vocab, tgt_vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "log(f\"Train dataset: {len(train_dataset)} examples\")\n",
        "log(f\"Train batches: {len(train_loader)}\")\n",
        "\n",
        "# Verify encoding/decoding\n",
        "log(\"\\nVerify encode/decode:\")\n",
        "for cmd, out, _ in train_data[:3]:\n",
        "    enc = tgt_vocab.encode(out, add_sos=True, add_eos=True)\n",
        "    dec = tgt_vocab.decode(enc)\n",
        "    log(f\"  '{out}' ‚Üí {enc} ‚Üí '{dec}' | Match: {dec == out}\")"
      ],
      "metadata": {"id": "dataset"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Models"
      ],
      "metadata": {"id": "models_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# HDC MODEL\n",
        "# ============================================================\n",
        "\n",
        "class HDCModel:\n",
        "    \"\"\"HDC uses structural composition - no training needed.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.primitives = {\n",
        "            'walk': 'WALK', 'run': 'RUN', 'jump': 'JUMP',\n",
        "            'look': 'LOOK', 'turn': 'TURN', 'spin': 'SPIN',\n",
        "            'crawl': 'CRAWL', 'swim': 'SWIM',\n",
        "        }\n",
        "        self.modifiers = {'twice': 2, 'thrice': 3, 'four times': 4}\n",
        "    \n",
        "    def predict(self, command):\n",
        "        command = command.strip().lower()\n",
        "        \n",
        "        if ' and ' in command:\n",
        "            parts = command.split(' and ')\n",
        "            if len(parts) == 2:\n",
        "                left = self._predict_single(parts[0].strip())\n",
        "                right = self._predict_single(parts[1].strip())\n",
        "                if left and right:\n",
        "                    return f\"{left} {right}\"\n",
        "        \n",
        "        return self._predict_single(command) or '<e>'\n",
        "    \n",
        "    def _predict_single(self, cmd):\n",
        "        repeat = 1\n",
        "        for mod_name, mod_count in self.modifiers.items():\n",
        "            if cmd.endswith(' ' + mod_name):\n",
        "                repeat = mod_count\n",
        "                cmd = cmd[:-len(mod_name)-1].strip()\n",
        "                break\n",
        "        \n",
        "        if cmd in self.primitives:\n",
        "            return ' '.join([self.primitives[cmd]] * repeat)\n",
        "        return None\n",
        "\n",
        "hdc = HDCModel()\n",
        "\n",
        "# Verify HDC\n",
        "log(\"HDC verification:\")\n",
        "test_cmds = ['walk', 'swim', 'walk twice', 'swim four times', 'walk and swim']\n",
        "for cmd in test_cmds:\n",
        "    log(f\"  '{cmd}' ‚Üí '{hdc.predict(cmd)}'\")"
      ],
      "metadata": {"id": "hdc"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRANSFORMER MODEL\n",
        "# ============================================================\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=128, nhead=4, \n",
        "                 num_layers=3, dim_ff=256, dropout=0.1, max_len=15):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
        "        \n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=dim_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "    \n",
        "    def forward(self, src, tgt):\n",
        "        B, src_len = src.shape\n",
        "        _, tgt_len = tgt.shape\n",
        "        \n",
        "        src_pos = torch.arange(src_len, device=src.device).unsqueeze(0).expand(B, -1)\n",
        "        tgt_pos = torch.arange(tgt_len, device=tgt.device).unsqueeze(0).expand(B, -1)\n",
        "        \n",
        "        src_emb = self.src_emb(src) + self.pos_emb(src_pos)\n",
        "        tgt_emb = self.tgt_emb(tgt) + self.pos_emb(tgt_pos)\n",
        "        \n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_len, device=src.device)\n",
        "        src_pad = (src == 0)\n",
        "        tgt_pad = (tgt == 0)\n",
        "        \n",
        "        out = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask,\n",
        "                               src_key_padding_mask=src_pad, tgt_key_padding_mask=tgt_pad)\n",
        "        \n",
        "        return self.fc_out(out)\n",
        "    \n",
        "    def generate(self, src, max_len=10):\n",
        "        self.eval()\n",
        "        B = src.size(0)\n",
        "        tgt = torch.ones(B, 1, dtype=torch.long, device=src.device)  # SOS\n",
        "        \n",
        "        for _ in range(max_len):\n",
        "            with torch.no_grad():\n",
        "                out = self.forward(src, tgt)\n",
        "                next_tok = out[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "                tgt = torch.cat([tgt, next_tok], dim=1)\n",
        "                if (next_tok == 2).all():  # EOS\n",
        "                    break\n",
        "        return tgt\n",
        "\n",
        "# Create model\n",
        "model = Seq2SeqTransformer(\n",
        "    src_vocab_size=src_vocab.n_words,\n",
        "    tgt_vocab_size=tgt_vocab.n_words,\n",
        "    d_model=128,\n",
        "    nhead=4,\n",
        "    num_layers=3,\n",
        "    dim_ff=256\n",
        ").to(device)\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "log(f\"Transformer: {n_params:,} parameters\")"
      ],
      "metadata": {"id": "transformer"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Training with Convergence Check"
      ],
      "metadata": {"id": "training_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRAINING WITH EARLY STOPPING\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_accuracy(model, examples, src_vocab, tgt_vocab, max_samples=100):\n",
        "    \"\"\"Calculate accuracy on a set of examples.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    samples = examples[:max_samples]\n",
        "    \n",
        "    for cmd, out, _ in samples:\n",
        "        src = src_vocab.encode(cmd.lower())\n",
        "        src = src[:12] + [0] * max(0, 12 - len(src))\n",
        "        src_t = torch.tensor([src], device=device)\n",
        "        \n",
        "        pred_tokens = model.generate(src_t, max_len=10)\n",
        "        pred = tgt_vocab.decode(pred_tokens[0])\n",
        "        \n",
        "        if pred == out:\n",
        "            correct += 1\n",
        "    \n",
        "    return correct / len(samples)\n",
        "\n",
        "def train_until_convergence(model, loader, train_data, src_vocab, tgt_vocab,\n",
        "                            max_epochs=300, target_acc=0.95, patience=20):\n",
        "    \"\"\"Train until train accuracy reaches target.\"\"\"\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    \n",
        "    history = {'loss': [], 'train_acc': []}\n",
        "    best_acc = 0\n",
        "    no_improve = 0\n",
        "    \n",
        "    log(f\"Training until {target_acc:.0%} accuracy or {max_epochs} epochs...\")\n",
        "    \n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        \n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            \n",
        "            tgt_in = tgt[:, :-1]\n",
        "            tgt_out = tgt[:, 1:]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_in)\n",
        "            \n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_out.reshape(-1))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        avg_loss = total_loss / len(loader)\n",
        "        scheduler.step(avg_loss)\n",
        "        \n",
        "        # Check accuracy every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            train_acc = evaluate_accuracy(model, train_data, src_vocab, tgt_vocab)\n",
        "            history['loss'].append(avg_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            \n",
        "            log(f\"Epoch {epoch+1}: loss={avg_loss:.4f}, train_acc={train_acc:.1%}\")\n",
        "            \n",
        "            if train_acc >= target_acc:\n",
        "                log(f\"‚úì Reached {target_acc:.0%} accuracy!\")\n",
        "                return history, epoch + 1\n",
        "            \n",
        "            if train_acc > best_acc:\n",
        "                best_acc = train_acc\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= patience // 10:\n",
        "                    log(f\"No improvement for {patience} epochs, stopping.\")\n",
        "                    break\n",
        "    \n",
        "    final_acc = evaluate_accuracy(model, train_data, src_vocab, tgt_vocab)\n",
        "    log(f\"Finished at epoch {epoch+1}, final train_acc={final_acc:.1%}\")\n",
        "    return history, epoch + 1\n",
        "\n",
        "# Train\n",
        "history, epochs_used = train_until_convergence(\n",
        "    model, train_loader, train_data, src_vocab, tgt_vocab,\n",
        "    max_epochs=300, target_acc=0.95\n",
        ")"
      ],
      "metadata": {"id": "training"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VERIFY TRAINING WORKED\n",
        "# ============================================================\n",
        "\n",
        "log(\"\\n\" + \"=\"*60)\n",
        "log(\"TRAINING VERIFICATION\")\n",
        "log(\"=\"*60)\n",
        "\n",
        "# Check on training examples\n",
        "log(\"\\nSample predictions on TRAINING data:\")\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "for cmd, out, _ in train_data[:20]:\n",
        "    src = src_vocab.encode(cmd.lower())\n",
        "    src = src[:12] + [0] * max(0, 12 - len(src))\n",
        "    src_t = torch.tensor([src], device=device)\n",
        "    \n",
        "    pred_tokens = model.generate(src_t, max_len=10)\n",
        "    pred = tgt_vocab.decode(pred_tokens[0])\n",
        "    \n",
        "    is_correct = pred == out\n",
        "    if is_correct:\n",
        "        correct += 1\n",
        "    \n",
        "    status = \"‚úì\" if is_correct else \"‚úó\"\n",
        "    log(f\"  {status} '{cmd}' ‚Üí '{pred}' (expected: '{out}')\")\n",
        "\n",
        "train_acc = correct / 20\n",
        "log(f\"\\nTrain accuracy (sample): {train_acc:.1%}\")\n",
        "\n",
        "# Full train accuracy\n",
        "full_train_acc = evaluate_accuracy(model, train_data, src_vocab, tgt_vocab, max_samples=len(train_data))\n",
        "log(f\"Train accuracy (full): {full_train_acc:.1%}\")\n",
        "\n",
        "RESULTS['train_accuracy'] = full_train_acc\n",
        "\n",
        "if full_train_acc < 0.8:\n",
        "    log(\"\\n‚ö†Ô∏è WARNING: Train accuracy < 80%. Model hasn't learned properly!\")\n",
        "    log(\"Results may not be meaningful.\")\n",
        "else:\n",
        "    log(\"\\n‚úì Model has learned the training data well.\")"
      ],
      "metadata": {"id": "verify_training"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Extrapolation Test"
      ],
      "metadata": {"id": "test_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# EXTRAPOLATION TEST\n",
        "# ============================================================\n",
        "\n",
        "log(\"\\n\" + \"=\"*60)\n",
        "log(\"EXTRAPOLATION TEST\")\n",
        "log(\"=\"*60)\n",
        "log(f\"Testing on {len(test_extrapolation)} held-out combinations\")\n",
        "log(f\"Model knows: '{HOLDOUT_PRIMITIVE}' and 'walk {HOLDOUT_MODIFIER}'\")\n",
        "log(f\"But has never seen other combinations with these.\")\n",
        "\n",
        "# HDC\n",
        "log(\"\\n--- HDC ---\")\n",
        "hdc_correct = 0\n",
        "hdc_results = []\n",
        "\n",
        "for cmd, expected, level in test_extrapolation:\n",
        "    pred = hdc.predict(cmd)\n",
        "    is_correct = pred == expected\n",
        "    if is_correct:\n",
        "        hdc_correct += 1\n",
        "    hdc_results.append((cmd, expected, pred, is_correct))\n",
        "\n",
        "hdc_acc = hdc_correct / len(test_extrapolation)\n",
        "log(f\"HDC Accuracy: {hdc_acc:.1%} ({hdc_correct}/{len(test_extrapolation)})\")\n",
        "\n",
        "# Show HDC samples\n",
        "log(\"Sample predictions:\")\n",
        "for cmd, expected, pred, correct in hdc_results[:5]:\n",
        "    status = \"‚úì\" if correct else \"‚úó\"\n",
        "    log(f\"  {status} '{cmd}' ‚Üí '{pred}' (expected: '{expected}')\")\n",
        "\n",
        "# Transformer\n",
        "log(\"\\n--- Transformer ---\")\n",
        "model.eval()\n",
        "trans_correct = 0\n",
        "trans_results = []\n",
        "\n",
        "for cmd, expected, level in test_extrapolation:\n",
        "    src = src_vocab.encode(cmd.lower())\n",
        "    src = src[:12] + [0] * max(0, 12 - len(src))\n",
        "    src_t = torch.tensor([src], device=device)\n",
        "    \n",
        "    pred_tokens = model.generate(src_t, max_len=10)\n",
        "    pred = tgt_vocab.decode(pred_tokens[0])\n",
        "    \n",
        "    is_correct = pred == expected\n",
        "    if is_correct:\n",
        "        trans_correct += 1\n",
        "    trans_results.append((cmd, expected, pred, is_correct))\n",
        "\n",
        "trans_acc = trans_correct / len(test_extrapolation)\n",
        "log(f\"Transformer Accuracy: {trans_acc:.1%} ({trans_correct}/{len(test_extrapolation)})\")\n",
        "\n",
        "# Show Transformer samples\n",
        "log(\"Sample predictions:\")\n",
        "for cmd, expected, pred, correct in trans_results[:10]:\n",
        "    status = \"‚úì\" if correct else \"‚úó\"\n",
        "    log(f\"  {status} '{cmd}' ‚Üí '{pred}' (expected: '{expected}')\")\n",
        "\n",
        "RESULTS['hdc_extrapolation'] = hdc_acc\n",
        "RESULTS['transformer_extrapolation'] = trans_acc"
      ],
      "metadata": {"id": "extrapolation"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ERROR ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "log(\"\\n\" + \"=\"*60)\n",
        "log(\"ERROR ANALYSIS\")\n",
        "log(\"=\"*60)\n",
        "\n",
        "# Group by type of extrapolation\n",
        "log(\"\\nTransformer errors by type:\")\n",
        "\n",
        "errors_by_type = defaultdict(list)\n",
        "for cmd, expected, pred, correct in trans_results:\n",
        "    if not correct:\n",
        "        if HOLDOUT_PRIMITIVE in cmd and HOLDOUT_MODIFIER in cmd:\n",
        "            errors_by_type['both_holdout'].append((cmd, expected, pred))\n",
        "        elif HOLDOUT_PRIMITIVE in cmd:\n",
        "            errors_by_type['holdout_primitive'].append((cmd, expected, pred))\n",
        "        elif HOLDOUT_MODIFIER in cmd:\n",
        "            errors_by_type['holdout_modifier'].append((cmd, expected, pred))\n",
        "\n",
        "for err_type, errors in errors_by_type.items():\n",
        "    log(f\"\\n{err_type}: {len(errors)} errors\")\n",
        "    for cmd, expected, pred in errors[:3]:\n",
        "        log(f\"  '{cmd}' ‚Üí '{pred}' (expected: '{expected}')\")"
      ],
      "metadata": {"id": "error_analysis"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Results Summary"
      ],
      "metadata": {"id": "summary_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "log(\"\\n\" + \"=\"*60)\n",
        "log(\"FINAL RESULTS\")\n",
        "log(\"=\"*60)\n",
        "\n",
        "log(f\"\\nDataset:\")\n",
        "log(f\"  Total examples: {len(all_examples)}\")\n",
        "log(f\"  Train: {len(train_data)} ({len(train_data)/len(all_examples):.1%})\")\n",
        "log(f\"  Test (extrapolation): {len(test_extrapolation)}\")\n",
        "\n",
        "log(f\"\\nHoldout elements:\")\n",
        "log(f\"  Primitive: '{HOLDOUT_PRIMITIVE}'\")\n",
        "log(f\"  Modifier: '{HOLDOUT_MODIFIER}'\")\n",
        "\n",
        "log(f\"\\nResults:\")\n",
        "log(f\"  {'Model':<20} {'Train Acc':<15} {'Extrapolation Acc':<20}\")\n",
        "log(f\"  {'-'*55}\")\n",
        "log(f\"  {'HDC':<20} {'100% (by design)':<15} {hdc_acc:<20.1%}\")\n",
        "log(f\"  {'Transformer':<20} {full_train_acc:<15.1%} {trans_acc:<20.1%}\")\n",
        "\n",
        "log(f\"\\n\" + \"=\"*60)\n",
        "if hdc_acc > trans_acc:\n",
        "    diff = hdc_acc - trans_acc\n",
        "    log(f\"HDC outperforms Transformer by {diff:.1%} on extrapolation\")\n",
        "    if full_train_acc >= 0.9:\n",
        "        log(\"\\n‚úì HYPOTHESIS SUPPORTED:\")\n",
        "        log(\"  Transformer learned the training data well but failed to generalize.\")\n",
        "        log(\"  HDC's structural composition enables perfect generalization.\")\n",
        "    else:\n",
        "        log(\"\\n‚ö†Ô∏è Transformer didn't fully learn training data.\")\n",
        "        log(\"  Results may not be conclusive.\")\n",
        "else:\n",
        "    log(f\"Transformer matches or exceeds HDC\")\n",
        "    log(\"Hypothesis not supported in this test.\")\n",
        "\n",
        "log(\"=\"*60)"
      ],
      "metadata": {"id": "summary"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# 1. Train vs Extrapolation\n",
        "ax = axes[0]\n",
        "models = ['HDC', 'Transformer']\n",
        "train_accs = [1.0, full_train_acc]\n",
        "extrap_accs = [hdc_acc, trans_acc]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(x - width/2, train_accs, width, label='Train', color='#3498db', alpha=0.8)\n",
        "ax.bar(x + width/2, extrap_accs, width, label='Extrapolation', color='#e74c3c', alpha=0.8)\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Train vs Extrapolation Accuracy')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.axhline(y=1.0, color='green', linestyle='--', alpha=0.3)\n",
        "\n",
        "for i, (t, e) in enumerate(zip(train_accs, extrap_accs)):\n",
        "    ax.text(i - width/2, t + 0.02, f'{t:.0%}', ha='center', fontsize=10)\n",
        "    ax.text(i + width/2, e + 0.02, f'{e:.0%}', ha='center', fontsize=10)\n",
        "\n",
        "# 2. Generalization Gap\n",
        "ax = axes[1]\n",
        "gaps = [t - e for t, e in zip(train_accs, extrap_accs)]\n",
        "colors = ['#27ae60' if g < 0.1 else '#e74c3c' for g in gaps]\n",
        "\n",
        "ax.bar(models, gaps, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax.set_ylabel('Gap (Train - Extrapolation)')\n",
        "ax.set_title('Generalization Gap\\n(Lower = Better)')\n",
        "ax.axhline(y=0, color='green', linestyle='--', alpha=0.5)\n",
        "\n",
        "for i, g in enumerate(gaps):\n",
        "    ax.text(i, g + 0.02, f'{g:.0%}', ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 3. Training curve\n",
        "ax = axes[2]\n",
        "if history['train_acc']:\n",
        "    epochs = range(10, 10 * len(history['train_acc']) + 1, 10)\n",
        "    ax.plot(epochs, history['train_acc'], 'b-o', label='Train Accuracy')\n",
        "    ax.axhline(y=0.95, color='green', linestyle='--', alpha=0.5, label='Target (95%)')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title('Training Progress')\n",
        "    ax.legend()\n",
        "    ax.set_ylim(0, 1.05)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fair_test_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "log(\"\\nüìä Saved: fair_test_results.png\")"
      ],
      "metadata": {"id": "visualization"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SAVE RESULTS\n",
        "# ============================================================\n",
        "\n",
        "RESULTS['end_time'] = datetime.now().isoformat()\n",
        "RESULTS['summary'] = {\n",
        "    'total_examples': len(all_examples),\n",
        "    'train_size': len(train_data),\n",
        "    'test_size': len(test_extrapolation),\n",
        "    'holdout_primitive': HOLDOUT_PRIMITIVE,\n",
        "    'holdout_modifier': HOLDOUT_MODIFIER,\n",
        "    'transformer_params': n_params,\n",
        "    'epochs_trained': epochs_used,\n",
        "    'train_accuracy': full_train_acc,\n",
        "    'hdc_extrapolation': hdc_acc,\n",
        "    'transformer_extrapolation': trans_acc,\n",
        "    'hypothesis_supported': hdc_acc > trans_acc and full_train_acc >= 0.9\n",
        "}\n",
        "\n",
        "with open('fair_test_results.json', 'w') as f:\n",
        "    json.dump(RESULTS, f, indent=2, default=str)\n",
        "\n",
        "log(\"\\nüìÑ Saved: fair_test_results.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FILES TO DOWNLOAD:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. fair_test_results.json\")\n",
        "print(\"2. fair_test_results.png\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {"id": "save"},
      "execution_count": null,
      "outputs": []
    }
  ]
}
