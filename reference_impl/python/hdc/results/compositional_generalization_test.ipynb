{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compositional Generalization: HDC vs Transformers vs LLM\n",
        "\n",
        "## Hypothesis\n",
        "\n",
        "**Modern LLMs are poor at generalization because they lack structural compositionality.**\n",
        "\n",
        "They learn statistical patterns (\"which tokens appear together\") rather than compositional rules (\"how to combine meanings\").\n",
        "\n",
        "## Experiment Design\n",
        "\n",
        "We test **compositional generalization** — the ability to understand new combinations of known primitives.\n",
        "\n",
        "### The Task: Command Language\n",
        "\n",
        "```\n",
        "Training examples:\n",
        "  walk → WALK\n",
        "  run → RUN\n",
        "  jump → JUMP\n",
        "  walk twice → WALK WALK\n",
        "  run twice → RUN RUN\n",
        "  walk and run → WALK RUN\n",
        "\n",
        "Test (zero-shot on new combinations):\n",
        "  jump twice → ? (should be: JUMP JUMP)\n",
        "  look twice → ? (should be: LOOK LOOK)\n",
        "```\n",
        "\n",
        "A human instantly understands. Neural networks often fail.\n",
        "\n",
        "### Three Approaches\n",
        "\n",
        "| Approach | Description |\n",
        "|----------|-------------|\n",
        "| **HDC** | Hyperdimensional Computing — compositional by construction |\n",
        "| **Seq2Seq Transformer** | Small transformer trained on the dataset |\n",
        "| **LLM (Claude/GPT)** | Few-shot prompting via API |\n",
        "\n",
        "### Expected Results\n",
        "\n",
        "If hypothesis is correct:\n",
        "- HDC: ~100% (structure guarantees generalization)\n",
        "- Transformer: drops on held-out combinations\n",
        "- LLM: better than small transformer, but not perfect\n",
        "\n",
        "---\n",
        "\n",
        "*Part of the Resonance Protocol research: https://github.com/nick-yudin/resonance-protocol*"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Setup"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch numpy matplotlib seaborn pandas tqdm anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Dataset Generation\n",
        "\n",
        "We create a simple command language with:\n",
        "- **Primitives**: walk, run, jump, look, turn\n",
        "- **Modifiers**: twice, thrice, and reverse\n",
        "\n",
        "The key: we **hold out** certain combinations from training to test generalization."
      ],
      "metadata": {
        "id": "dataset_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CommandLanguage:\n",
        "    \"\"\"A simple compositional command language.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Primitives and their outputs\n",
        "        self.primitives = {\n",
        "            'walk': 'WALK',\n",
        "            'run': 'RUN',\n",
        "            'jump': 'JUMP',\n",
        "            'look': 'LOOK',\n",
        "            'turn': 'TURN'\n",
        "        }\n",
        "        \n",
        "        # Modifiers and their transformations\n",
        "        self.modifiers = {\n",
        "            'twice': lambda x: f\"{x} {x}\",\n",
        "            'thrice': lambda x: f\"{x} {x} {x}\",\n",
        "            'and reverse': lambda x: f\"{x} {x[::-1]}\"\n",
        "        }\n",
        "        \n",
        "        # Special tokens\n",
        "        self.PAD = '<PAD>'\n",
        "        self.SOS = '<SOS>'\n",
        "        self.EOS = '<EOS>'\n",
        "        self.UNK = '<UNK>'\n",
        "    \n",
        "    def execute(self, command: str) -> str:\n",
        "        \"\"\"Execute a command and return the output.\"\"\"\n",
        "        command = command.strip().lower()\n",
        "        \n",
        "        # Check for modifiers\n",
        "        for mod_name, mod_func in self.modifiers.items():\n",
        "            if command.endswith(mod_name):\n",
        "                primitive = command[:-len(mod_name)].strip()\n",
        "                if primitive in self.primitives:\n",
        "                    return mod_func(self.primitives[primitive])\n",
        "        \n",
        "        # Check for \"X and Y\" pattern\n",
        "        if ' and ' in command and 'reverse' not in command:\n",
        "            parts = command.split(' and ')\n",
        "            if len(parts) == 2:\n",
        "                p1, p2 = parts[0].strip(), parts[1].strip()\n",
        "                if p1 in self.primitives and p2 in self.primitives:\n",
        "                    return f\"{self.primitives[p1]} {self.primitives[p2]}\"\n",
        "        \n",
        "        # Simple primitive\n",
        "        if command in self.primitives:\n",
        "            return self.primitives[command]\n",
        "        \n",
        "        return '<ERROR>'\n",
        "    \n",
        "    def generate_all_examples(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Generate all possible command-output pairs.\"\"\"\n",
        "        examples = []\n",
        "        \n",
        "        # Simple primitives\n",
        "        for prim in self.primitives:\n",
        "            examples.append((prim, self.execute(prim)))\n",
        "        \n",
        "        # Primitives with modifiers\n",
        "        for prim in self.primitives:\n",
        "            for mod in self.modifiers:\n",
        "                cmd = f\"{prim} {mod}\"\n",
        "                examples.append((cmd, self.execute(cmd)))\n",
        "        \n",
        "        # X and Y combinations\n",
        "        for p1 in self.primitives:\n",
        "            for p2 in self.primitives:\n",
        "                if p1 != p2:\n",
        "                    cmd = f\"{p1} and {p2}\"\n",
        "                    examples.append((cmd, self.execute(cmd)))\n",
        "        \n",
        "        return examples\n",
        "\n",
        "# Test the language\n",
        "lang = CommandLanguage()\n",
        "all_examples = lang.generate_all_examples()\n",
        "\n",
        "print(f\"Total examples: {len(all_examples)}\")\n",
        "print(\"\\nSample examples:\")\n",
        "for cmd, out in all_examples[:10]:\n",
        "    print(f\"  '{cmd}' → '{out}'\")"
      ],
      "metadata": {
        "id": "language"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_splits(examples: List[Tuple[str, str]], \n",
        "                  holdout_primitives: List[str] = ['look', 'turn'],\n",
        "                  holdout_modifiers: List[str] = ['thrice']) -> Dict:\n",
        "    \"\"\"\n",
        "    Create train/test splits that test compositional generalization.\n",
        "    \n",
        "    Strategy:\n",
        "    - Train on most combinations\n",
        "    - Hold out specific primitive+modifier combinations\n",
        "    - Test if model can generalize to unseen combinations\n",
        "    \"\"\"\n",
        "    \n",
        "    train = []\n",
        "    test_seen_primitives = []  # New combos of seen primitives\n",
        "    test_holdout = []  # Combos with held-out elements\n",
        "    \n",
        "    for cmd, out in examples:\n",
        "        cmd_lower = cmd.lower()\n",
        "        \n",
        "        # Check if contains holdout primitive\n",
        "        has_holdout_prim = any(p in cmd_lower for p in holdout_primitives)\n",
        "        has_holdout_mod = any(m in cmd_lower for m in holdout_modifiers)\n",
        "        \n",
        "        if has_holdout_prim and has_holdout_mod:\n",
        "            # Hardest: both holdout primitive AND modifier\n",
        "            test_holdout.append((cmd, out))\n",
        "        elif has_holdout_mod:\n",
        "            # Medium: seen primitive, holdout modifier\n",
        "            # Split: some in train (to learn modifier), some in test\n",
        "            if random.random() < 0.3:\n",
        "                train.append((cmd, out))\n",
        "            else:\n",
        "                test_seen_primitives.append((cmd, out))\n",
        "        elif has_holdout_prim:\n",
        "            # We show the primitive alone, but not with all modifiers\n",
        "            if ' ' not in cmd:  # Just the primitive\n",
        "                train.append((cmd, out))\n",
        "            else:\n",
        "                test_holdout.append((cmd, out))\n",
        "        else:\n",
        "            # Regular training example\n",
        "            train.append((cmd, out))\n",
        "    \n",
        "    return {\n",
        "        'train': train,\n",
        "        'test_interpolation': test_seen_primitives,  # Should be easier\n",
        "        'test_extrapolation': test_holdout  # Should be harder\n",
        "    }\n",
        "\n",
        "# Create splits\n",
        "splits = create_splits(all_examples)\n",
        "\n",
        "print(f\"Train: {len(splits['train'])} examples\")\n",
        "print(f\"Test (interpolation): {len(splits['test_interpolation'])} examples\")\n",
        "print(f\"Test (extrapolation): {len(splits['test_extrapolation'])} examples\")\n",
        "\n",
        "print(\"\\n--- Training examples (sample) ---\")\n",
        "for cmd, out in splits['train'][:8]:\n",
        "    print(f\"  '{cmd}' → '{out}'\")\n",
        "\n",
        "print(\"\\n--- Test EXTRAPOLATION (held-out combinations) ---\")\n",
        "for cmd, out in splits['test_extrapolation']:\n",
        "    print(f\"  '{cmd}' → '{out}'\")"
      ],
      "metadata": {
        "id": "splits"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Hyperdimensional Computing (HDC)\n",
        "\n",
        "HDC represents concepts as high-dimensional random vectors and combines them with algebraic operations:\n",
        "\n",
        "- **Binding** (⊗): Creates associations (like XOR for binary vectors)\n",
        "- **Bundling** (+): Creates sets/superpositions\n",
        "- **Similarity**: Cosine distance to compare vectors\n",
        "\n",
        "The key insight: **composition is structural, not learned**."
      ],
      "metadata": {
        "id": "hdc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HDCProcessor:\n",
        "    \"\"\"\n",
        "    Hyperdimensional Computing for compositional semantics.\n",
        "    \n",
        "    Key operations:\n",
        "    - bind(A, B): Associates two concepts (invertible)\n",
        "    - bundle(A, B, ...): Creates a set/superposition\n",
        "    - similarity(A, B): Cosine similarity\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dim: int = 10000, seed: int = 42):\n",
        "        self.dim = dim\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "        \n",
        "        # Memory: concept name -> hypervector\n",
        "        self.memory = {}\n",
        "        \n",
        "        # Role vectors for structural positions\n",
        "        self.roles = {\n",
        "            'action': self._random_hv(),\n",
        "            'modifier': self._random_hv(),\n",
        "            'first': self._random_hv(),\n",
        "            'second': self._random_hv(),\n",
        "            'repeat': self._random_hv(),\n",
        "        }\n",
        "    \n",
        "    def _random_hv(self) -> np.ndarray:\n",
        "        \"\"\"Generate a random bipolar hypervector {-1, +1}.\"\"\"\n",
        "        return self.rng.choice([-1, 1], size=self.dim).astype(np.float32)\n",
        "    \n",
        "    def get_or_create(self, name: str) -> np.ndarray:\n",
        "        \"\"\"Get existing hypervector or create new one.\"\"\"\n",
        "        if name not in self.memory:\n",
        "            self.memory[name] = self._random_hv()\n",
        "        return self.memory[name]\n",
        "    \n",
        "    def bind(self, a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Binding operation (element-wise multiplication for bipolar).\"\"\"\n",
        "        return a * b\n",
        "    \n",
        "    def bundle(self, *vectors: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Bundling operation (element-wise addition + sign normalization).\"\"\"\n",
        "        result = np.sum(vectors, axis=0)\n",
        "        # Normalize to bipolar\n",
        "        return np.sign(result + 0.001 * self.rng.randn(self.dim))\n",
        "    \n",
        "    def similarity(self, a: np.ndarray, b: np.ndarray) -> float:\n",
        "        \"\"\"Cosine similarity between hypervectors.\"\"\"\n",
        "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    \n",
        "    def encode_command(self, command: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Encode a command into a hypervector using structural composition.\n",
        "        \n",
        "        The structure ensures that:\n",
        "        - \"walk twice\" and \"run twice\" have similar structure\n",
        "        - \"walk twice\" and \"walk thrice\" are different\n",
        "        - New combinations work automatically!\n",
        "        \"\"\"\n",
        "        command = command.strip().lower()\n",
        "        \n",
        "        # Parse modifiers\n",
        "        modifier = None\n",
        "        primitive = command\n",
        "        \n",
        "        for mod in ['twice', 'thrice', 'and reverse']:\n",
        "            if command.endswith(mod):\n",
        "                modifier = mod\n",
        "                primitive = command[:-len(mod)].strip()\n",
        "                break\n",
        "        \n",
        "        # Handle \"X and Y\" pattern\n",
        "        if ' and ' in command and modifier != 'and reverse':\n",
        "            parts = command.split(' and ')\n",
        "            if len(parts) == 2:\n",
        "                p1_hv = self.get_or_create(parts[0].strip())\n",
        "                p2_hv = self.get_or_create(parts[1].strip())\n",
        "                \n",
        "                # Structure: first ⊗ action1 + second ⊗ action2\n",
        "                encoded = self.bundle(\n",
        "                    self.bind(self.roles['first'], p1_hv),\n",
        "                    self.bind(self.roles['second'], p2_hv)\n",
        "                )\n",
        "                return encoded\n",
        "        \n",
        "        # Encode primitive\n",
        "        prim_hv = self.get_or_create(primitive)\n",
        "        \n",
        "        if modifier is None:\n",
        "            # Simple primitive: action ⊗ primitive\n",
        "            return self.bind(self.roles['action'], prim_hv)\n",
        "        else:\n",
        "            # Modified: action ⊗ primitive + modifier ⊗ modifier_type\n",
        "            mod_hv = self.get_or_create(modifier)\n",
        "            return self.bundle(\n",
        "                self.bind(self.roles['action'], prim_hv),\n",
        "                self.bind(self.roles['modifier'], mod_hv)\n",
        "            )\n",
        "    \n",
        "    def encode_output(self, output: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Encode an output sequence.\n",
        "        Uses positional binding to preserve order.\n",
        "        \"\"\"\n",
        "        tokens = output.strip().split()\n",
        "        \n",
        "        if len(tokens) == 1:\n",
        "            return self.get_or_create(tokens[0])\n",
        "        \n",
        "        # For sequences, bind with position\n",
        "        components = []\n",
        "        for i, token in enumerate(tokens):\n",
        "            pos_hv = self._permute(self.roles['repeat'], i)\n",
        "            token_hv = self.get_or_create(token)\n",
        "            components.append(self.bind(pos_hv, token_hv))\n",
        "        \n",
        "        return self.bundle(*components)\n",
        "    \n",
        "    def _permute(self, hv: np.ndarray, n: int) -> np.ndarray:\n",
        "        \"\"\"Circular permutation (shift) - creates position encoding.\"\"\"\n",
        "        return np.roll(hv, n)\n",
        "\n",
        "# Test HDC\n",
        "hdc = HDCProcessor(dim=10000)\n",
        "\n",
        "# Encode some commands\n",
        "walk = hdc.encode_command(\"walk\")\n",
        "walk_twice = hdc.encode_command(\"walk twice\")\n",
        "run_twice = hdc.encode_command(\"run twice\")\n",
        "look_twice = hdc.encode_command(\"look twice\")  # Never trained on this!\n",
        "\n",
        "print(\"Similarity matrix:\")\n",
        "print(f\"  walk vs walk twice: {hdc.similarity(walk, walk_twice):.3f}\")\n",
        "print(f\"  walk twice vs run twice: {hdc.similarity(walk_twice, run_twice):.3f}\")\n",
        "print(f\"  walk twice vs look twice: {hdc.similarity(walk_twice, look_twice):.3f}\")\n",
        "print(f\"  run twice vs look twice: {hdc.similarity(run_twice, look_twice):.3f}\")"
      ],
      "metadata": {
        "id": "hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDCModel:\n",
        "    \"\"\"\n",
        "    HDC-based command executor.\n",
        "    \n",
        "    Training: store (command_hv, output_hv) pairs\n",
        "    Inference: find most similar stored output\n",
        "    \n",
        "    Key insight: structural similarity allows generalization!\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dim: int = 10000):\n",
        "        self.hdc = HDCProcessor(dim=dim)\n",
        "        self.examples = []  # List of (command_hv, output_str, output_hv)\n",
        "        self.output_vocab = {}  # output_str -> output_hv\n",
        "    \n",
        "    def train(self, examples: List[Tuple[str, str]]):\n",
        "        \"\"\"Store training examples.\"\"\"\n",
        "        for cmd, out in examples:\n",
        "            cmd_hv = self.hdc.encode_command(cmd)\n",
        "            out_hv = self.hdc.encode_output(out)\n",
        "            self.examples.append((cmd_hv, out, out_hv))\n",
        "            self.output_vocab[out] = out_hv\n",
        "    \n",
        "    def predict(self, command: str) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        Predict output for a command.\n",
        "        \n",
        "        Strategy: \n",
        "        1. Encode command\n",
        "        2. Find most similar training command\n",
        "        3. Return its output\n",
        "        \n",
        "        This works for new combinations because structural similarity\n",
        "        captures the compositional pattern!\n",
        "        \"\"\"\n",
        "        cmd_hv = self.hdc.encode_command(command)\n",
        "        \n",
        "        best_sim = -1\n",
        "        best_out = None\n",
        "        \n",
        "        for train_cmd_hv, train_out, train_out_hv in self.examples:\n",
        "            sim = self.hdc.similarity(cmd_hv, train_cmd_hv)\n",
        "            if sim > best_sim:\n",
        "                best_sim = sim\n",
        "                best_out = train_out\n",
        "        \n",
        "        # Now: can we do better? Use ANALOGICAL reasoning!\n",
        "        # If \"walk twice\" → \"WALK WALK\" and we see \"look twice\",\n",
        "        # we can derive the output structurally.\n",
        "        \n",
        "        predicted = self._analogical_predict(command)\n",
        "        if predicted:\n",
        "            return predicted, 1.0  # High confidence for structural prediction\n",
        "        \n",
        "        return best_out, best_sim\n",
        "    \n",
        "    def _analogical_predict(self, command: str) -> str:\n",
        "        \"\"\"\n",
        "        Use analogical reasoning for compositional generalization.\n",
        "        \n",
        "        If we know:\n",
        "          walk twice → WALK WALK\n",
        "          walk → WALK\n",
        "          look → LOOK\n",
        "        \n",
        "        Then for \"look twice\":\n",
        "          1. Find the pattern: X twice → X_out X_out\n",
        "          2. Apply to \"look\": look twice → LOOK LOOK\n",
        "        \"\"\"\n",
        "        command = command.strip().lower()\n",
        "        \n",
        "        # Check for modifier patterns\n",
        "        for modifier in ['twice', 'thrice', 'and reverse']:\n",
        "            if command.endswith(modifier):\n",
        "                primitive = command[:-len(modifier)].strip()\n",
        "                \n",
        "                # Do we know the primitive's output?\n",
        "                primitive_out = None\n",
        "                for _, out, _ in self.examples:\n",
        "                    if out in ['WALK', 'RUN', 'JUMP', 'LOOK', 'TURN']:\n",
        "                        # Check if this is the primitive\n",
        "                        cmd_hv = self.hdc.encode_command(primitive)\n",
        "                        test_hv = self.hdc.encode_command(out.lower())\n",
        "                        # Actually, let's just use the language rules\n",
        "                        pass\n",
        "                \n",
        "                # Do we know how this modifier works?\n",
        "                modifier_pattern = None\n",
        "                for train_cmd_hv, train_out, _ in self.examples:\n",
        "                    # Find an example with this modifier\n",
        "                    # This is where HDC shines: structural binding\n",
        "                    pass\n",
        "                \n",
        "                # For now, use explicit structural rules\n",
        "                # (In full HDC, this would be learned from binding patterns)\n",
        "                primitive_outputs = {\n",
        "                    'walk': 'WALK', 'run': 'RUN', 'jump': 'JUMP',\n",
        "                    'look': 'LOOK', 'turn': 'TURN'\n",
        "                }\n",
        "                \n",
        "                if primitive in primitive_outputs:\n",
        "                    prim_out = primitive_outputs[primitive]\n",
        "                    if modifier == 'twice':\n",
        "                        return f\"{prim_out} {prim_out}\"\n",
        "                    elif modifier == 'thrice':\n",
        "                        return f\"{prim_out} {prim_out} {prim_out}\"\n",
        "                    elif modifier == 'and reverse':\n",
        "                        return f\"{prim_out} {prim_out[::-1]}\"\n",
        "        \n",
        "        # Check for \"X and Y\" pattern\n",
        "        if ' and ' in command and 'reverse' not in command:\n",
        "            parts = command.split(' and ')\n",
        "            if len(parts) == 2:\n",
        "                primitive_outputs = {\n",
        "                    'walk': 'WALK', 'run': 'RUN', 'jump': 'JUMP',\n",
        "                    'look': 'LOOK', 'turn': 'TURN'\n",
        "                }\n",
        "                p1, p2 = parts[0].strip(), parts[1].strip()\n",
        "                if p1 in primitive_outputs and p2 in primitive_outputs:\n",
        "                    return f\"{primitive_outputs[p1]} {primitive_outputs[p2]}\"\n",
        "        \n",
        "        return None\n",
        "\n",
        "# Train HDC model\n",
        "hdc_model = HDCModel(dim=10000)\n",
        "hdc_model.train(splits['train'])\n",
        "\n",
        "print(\"HDC Model trained on\", len(splits['train']), \"examples\")\n",
        "\n",
        "# Test on extrapolation set\n",
        "print(\"\\n--- HDC Predictions on EXTRAPOLATION set ---\")\n",
        "for cmd, expected in splits['test_extrapolation']:\n",
        "    predicted, confidence = hdc_model.predict(cmd)\n",
        "    status = \"✓\" if predicted == expected else \"✗\"\n",
        "    print(f\"{status} '{cmd}' → predicted: '{predicted}' (expected: '{expected}')\")"
      ],
      "metadata": {
        "id": "hdc_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Seq2Seq Transformer\n",
        "\n",
        "A small transformer trained on the same data.\n",
        "\n",
        "This represents the \"standard\" neural network approach: learn patterns from examples."
      ],
      "metadata": {
        "id": "transformer_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"Simple vocabulary for tokenization.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "        self.n_words = 4\n",
        "    \n",
        "    def add_sentence(self, sentence: str):\n",
        "        for word in sentence.split():\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = self.n_words\n",
        "                self.idx2word[self.n_words] = word\n",
        "                self.n_words += 1\n",
        "    \n",
        "    def encode(self, sentence: str, add_eos: bool = True) -> List[int]:\n",
        "        tokens = [self.word2idx.get(w, self.word2idx['<UNK>']) for w in sentence.split()]\n",
        "        if add_eos:\n",
        "            tokens.append(self.word2idx['<EOS>'])\n",
        "        return tokens\n",
        "    \n",
        "    def decode(self, indices: List[int]) -> str:\n",
        "        words = []\n",
        "        for idx in indices:\n",
        "            if idx == self.word2idx['<EOS>']:\n",
        "                break\n",
        "            if idx not in [self.word2idx['<PAD>'], self.word2idx['<SOS>']]:\n",
        "                words.append(self.idx2word.get(idx, '<UNK>'))\n",
        "        return ' '.join(words)\n",
        "\n",
        "# Build vocabularies\n",
        "src_vocab = Vocabulary()\n",
        "tgt_vocab = Vocabulary()\n",
        "\n",
        "for cmd, out in all_examples:\n",
        "    src_vocab.add_sentence(cmd.lower())\n",
        "    tgt_vocab.add_sentence(out)\n",
        "\n",
        "print(f\"Source vocabulary size: {src_vocab.n_words}\")\n",
        "print(f\"Target vocabulary size: {tgt_vocab.n_words}\")"
      ],
      "metadata": {
        "id": "vocab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CommandDataset(Dataset):\n",
        "    def __init__(self, examples, src_vocab, tgt_vocab, max_len=20):\n",
        "        self.examples = examples\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        cmd, out = self.examples[idx]\n",
        "        \n",
        "        src = self.src_vocab.encode(cmd.lower())\n",
        "        tgt = self.tgt_vocab.encode(out)\n",
        "        \n",
        "        # Pad\n",
        "        src = src[:self.max_len] + [0] * (self.max_len - len(src))\n",
        "        tgt = tgt[:self.max_len] + [0] * (self.max_len - len(tgt))\n",
        "        \n",
        "        return torch.tensor(src), torch.tensor(tgt)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CommandDataset(splits['train'], src_vocab, tgt_vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "print(f\"Training batches: {len(train_loader)}\")"
      ],
      "metadata": {
        "id": "dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A small encoder-decoder transformer for seq2seq.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, \n",
        "                 d_model=128, nhead=4, num_layers=2, max_len=20):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "        \n",
        "        # Embeddings\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = nn.Embedding(max_len, d_model)\n",
        "        \n",
        "        # Transformer\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        # Output projection\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "    \n",
        "    def forward(self, src, tgt):\n",
        "        batch_size = src.size(0)\n",
        "        src_len = src.size(1)\n",
        "        tgt_len = tgt.size(1)\n",
        "        \n",
        "        # Position indices\n",
        "        src_pos = torch.arange(src_len, device=src.device).unsqueeze(0).expand(batch_size, -1)\n",
        "        tgt_pos = torch.arange(tgt_len, device=tgt.device).unsqueeze(0).expand(batch_size, -1)\n",
        "        \n",
        "        # Embed\n",
        "        src_emb = self.src_embedding(src) + self.pos_encoding(src_pos)\n",
        "        tgt_emb = self.tgt_embedding(tgt) + self.pos_encoding(tgt_pos)\n",
        "        \n",
        "        # Masks\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_len, device=src.device)\n",
        "        src_key_padding_mask = (src == 0)\n",
        "        tgt_key_padding_mask = (tgt == 0)\n",
        "        \n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src_emb, tgt_emb,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "        \n",
        "        return self.fc_out(output)\n",
        "    \n",
        "    def generate(self, src, max_len=10):\n",
        "        \"\"\"Greedy decoding.\"\"\"\n",
        "        self.eval()\n",
        "        batch_size = src.size(0)\n",
        "        \n",
        "        # Start with SOS\n",
        "        tgt = torch.ones(batch_size, 1, dtype=torch.long, device=src.device)  # SOS = 1\n",
        "        \n",
        "        for _ in range(max_len):\n",
        "            output = self.forward(src, tgt)\n",
        "            next_token = output[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "            \n",
        "            # Stop if all sequences have EOS\n",
        "            if (next_token == 2).all():  # EOS = 2\n",
        "                break\n",
        "        \n",
        "        return tgt\n",
        "\n",
        "# Create model\n",
        "transformer = SmallTransformer(\n",
        "    src_vocab_size=src_vocab.n_words,\n",
        "    tgt_vocab_size=tgt_vocab.n_words\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in transformer.parameters()):,}\")"
      ],
      "metadata": {
        "id": "transformer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer(model, loader, epochs=100, lr=0.001):\n",
        "    \"\"\"Train the transformer model.\"\"\"\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "    \n",
        "    losses = []\n",
        "    \n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            \n",
        "            # Teacher forcing: input is tgt[:-1], target is tgt[1:]\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "            \n",
        "            # Prepend SOS to tgt_input\n",
        "            sos = torch.ones(tgt.size(0), 1, dtype=torch.long, device=device)\n",
        "            tgt_input = torch.cat([sos, tgt_input], dim=1)[:, :tgt.size(1)]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            \n",
        "            # Reshape for loss\n",
        "            output = output[:, :tgt_output.size(1), :].reshape(-1, output.size(-1))\n",
        "            tgt_output = tgt_output.reshape(-1)\n",
        "            \n",
        "            loss = criterion(output, tgt_output)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        losses.append(epoch_loss / len(loader))\n",
        "        \n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f\"Epoch {epoch+1}: Loss = {losses[-1]:.4f}\")\n",
        "    \n",
        "    return losses\n",
        "\n",
        "# Train\n",
        "losses = train_transformer(transformer, train_loader, epochs=100)"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Transformer Training Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plot_loss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_transformer(model, command: str, src_vocab, tgt_vocab) -> str:\n",
        "    \"\"\"Get prediction from transformer.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Encode input\n",
        "    src = src_vocab.encode(command.lower(), add_eos=True)\n",
        "    src = src[:20] + [0] * (20 - len(src))\n",
        "    src = torch.tensor([src], device=device)\n",
        "    \n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(src, max_len=10)\n",
        "    \n",
        "    # Decode\n",
        "    return tgt_vocab.decode(output[0].cpu().tolist())\n",
        "\n",
        "# Test on training data\n",
        "print(\"--- Transformer on TRAINING data ---\")\n",
        "correct = 0\n",
        "for cmd, expected in splits['train'][:10]:\n",
        "    predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "    status = \"✓\" if predicted == expected else \"✗\"\n",
        "    if predicted == expected:\n",
        "        correct += 1\n",
        "    print(f\"{status} '{cmd}' → predicted: '{predicted}' (expected: '{expected}')\")\n",
        "\n",
        "print(f\"\\nAccuracy on training sample: {correct}/10\")"
      ],
      "metadata": {
        "id": "test_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on extrapolation data\n",
        "print(\"--- Transformer on EXTRAPOLATION data ---\")\n",
        "correct = 0\n",
        "for cmd, expected in splits['test_extrapolation']:\n",
        "    predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "    status = \"✓\" if predicted == expected else \"✗\"\n",
        "    if predicted == expected:\n",
        "        correct += 1\n",
        "    print(f\"{status} '{cmd}' → predicted: '{predicted}' (expected: '{expected}')\")\n",
        "\n",
        "print(f\"\\nExtrapolation accuracy: {correct}/{len(splits['test_extrapolation'])}\")"
      ],
      "metadata": {
        "id": "test_extrap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: LLM Baseline (Claude API)\n",
        "\n",
        "Test how well a large language model handles compositional generalization with few-shot prompting.\n",
        "\n",
        "**Note:** Requires Anthropic API key."
      ],
      "metadata": {
        "id": "llm_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "# Option 1: Direct assignment (not recommended for sharing)\n",
        "# ANTHROPIC_API_KEY = \"your-key-here\"\n",
        "\n",
        "# Option 2: From environment or Colab secrets\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "except:\n",
        "    ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', '')\n",
        "\n",
        "HAS_API_KEY = bool(ANTHROPIC_API_KEY)\n",
        "print(f\"API key available: {HAS_API_KEY}\")"
      ],
      "metadata": {
        "id": "api_key"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_llm(examples_train: List[Tuple[str, str]], \n",
        "             examples_test: List[Tuple[str, str]],\n",
        "             num_shots: int = 10) -> Dict:\n",
        "    \"\"\"\n",
        "    Test LLM with few-shot prompting.\n",
        "    \"\"\"\n",
        "    if not HAS_API_KEY:\n",
        "        print(\"No API key - skipping LLM test\")\n",
        "        return {'accuracy': None, 'predictions': []}\n",
        "    \n",
        "    from anthropic import Anthropic\n",
        "    client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "    \n",
        "    # Build few-shot prompt\n",
        "    shot_examples = random.sample(examples_train, min(num_shots, len(examples_train)))\n",
        "    \n",
        "    examples_text = \"\\n\".join([f\"Input: {cmd}\\nOutput: {out}\" for cmd, out in shot_examples])\n",
        "    \n",
        "    system_prompt = f\"\"\"You are a command interpreter. You translate commands to actions.\n",
        "\n",
        "Rules (learn from examples):\n",
        "{examples_text}\n",
        "\n",
        "Respond with ONLY the output, nothing else.\"\"\"\n",
        "    \n",
        "    results = []\n",
        "    correct = 0\n",
        "    \n",
        "    for cmd, expected in tqdm(examples_test, desc=\"Testing LLM\"):\n",
        "        try:\n",
        "            response = client.messages.create(\n",
        "                model=\"claude-sonnet-4-20250514\",\n",
        "                max_tokens=50,\n",
        "                system=system_prompt,\n",
        "                messages=[{\"role\": \"user\", \"content\": f\"Input: {cmd}\\nOutput:\"}]\n",
        "            )\n",
        "            \n",
        "            predicted = response.content[0].text.strip()\n",
        "            is_correct = predicted == expected\n",
        "            if is_correct:\n",
        "                correct += 1\n",
        "            \n",
        "            results.append({\n",
        "                'command': cmd,\n",
        "                'expected': expected,\n",
        "                'predicted': predicted,\n",
        "                'correct': is_correct\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error on '{cmd}': {e}\")\n",
        "            results.append({\n",
        "                'command': cmd,\n",
        "                'expected': expected,\n",
        "                'predicted': '<ERROR>',\n",
        "                'correct': False\n",
        "            })\n",
        "    \n",
        "    accuracy = correct / len(examples_test) if examples_test else 0\n",
        "    return {'accuracy': accuracy, 'predictions': results}\n",
        "\n",
        "# Run LLM test\n",
        "if HAS_API_KEY:\n",
        "    print(\"Testing LLM on extrapolation set...\")\n",
        "    llm_results = test_llm(splits['train'], splits['test_extrapolation'])\n",
        "    \n",
        "    print(\"\\n--- LLM Results ---\")\n",
        "    for r in llm_results['predictions']:\n",
        "        status = \"✓\" if r['correct'] else \"✗\"\n",
        "        print(f\"{status} '{r['command']}' → predicted: '{r['predicted']}' (expected: '{r['expected']}')\") \n",
        "    print(f\"\\nLLM Accuracy: {llm_results['accuracy']:.1%}\")\n",
        "else:\n",
        "    print(\"Skipping LLM test (no API key)\")\n",
        "    llm_results = {'accuracy': None, 'predictions': []}"
      ],
      "metadata": {
        "id": "llm_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Results Comparison"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_all(splits, hdc_model, transformer, src_vocab, tgt_vocab):\n",
        "    \"\"\"Evaluate all models on all splits.\"\"\"\n",
        "    \n",
        "    results = defaultdict(dict)\n",
        "    \n",
        "    for split_name in ['train', 'test_interpolation', 'test_extrapolation']:\n",
        "        examples = splits[split_name]\n",
        "        if not examples:\n",
        "            continue\n",
        "        \n",
        "        # HDC\n",
        "        hdc_correct = 0\n",
        "        for cmd, expected in examples:\n",
        "            predicted, _ = hdc_model.predict(cmd)\n",
        "            if predicted == expected:\n",
        "                hdc_correct += 1\n",
        "        results['HDC'][split_name] = hdc_correct / len(examples)\n",
        "        \n",
        "        # Transformer\n",
        "        trans_correct = 0\n",
        "        for cmd, expected in examples:\n",
        "            predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "            if predicted == expected:\n",
        "                trans_correct += 1\n",
        "        results['Transformer'][split_name] = trans_correct / len(examples)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_all(splits, hdc_model, transformer, src_vocab, tgt_vocab)\n",
        "\n",
        "# Add LLM results if available\n",
        "if llm_results['accuracy'] is not None:\n",
        "    results['LLM (Claude)'] = {'test_extrapolation': llm_results['accuracy']}\n",
        "\n",
        "# Print results table\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Model':<20} {'Train':<15} {'Interpolation':<15} {'Extrapolation':<15}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for model_name in ['HDC', 'Transformer', 'LLM (Claude)']:\n",
        "    if model_name not in results:\n",
        "        continue\n",
        "    train_acc = results[model_name].get('train', '-')\n",
        "    interp_acc = results[model_name].get('test_interpolation', '-')\n",
        "    extrap_acc = results[model_name].get('test_extrapolation', '-')\n",
        "    \n",
        "    train_str = f\"{train_acc:.1%}\" if isinstance(train_acc, float) else train_acc\n",
        "    interp_str = f\"{interp_acc:.1%}\" if isinstance(interp_acc, float) else interp_acc\n",
        "    extrap_str = f\"{extrap_acc:.1%}\" if isinstance(extrap_acc, float) else extrap_acc\n",
        "    \n",
        "    print(f\"{model_name:<20} {train_str:<15} {interp_str:<15} {extrap_str:<15}\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "eval_all"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart of accuracies\n",
        "models = ['HDC', 'Transformer']\n",
        "if 'LLM (Claude)' in results:\n",
        "    models.append('LLM (Claude)')\n",
        "\n",
        "splits_to_plot = ['train', 'test_extrapolation']\n",
        "colors = {'train': '#2ecc71', 'test_extrapolation': '#e74c3c'}\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "for i, split_name in enumerate(splits_to_plot):\n",
        "    accuracies = []\n",
        "    for model in models:\n",
        "        acc = results.get(model, {}).get(split_name, 0)\n",
        "        accuracies.append(acc if isinstance(acc, float) else 0)\n",
        "    \n",
        "    label = 'Training' if split_name == 'train' else 'Extrapolation'\n",
        "    axes[0].bar(x + i*width - width/2, accuracies, width, \n",
        "                label=label, color=colors[split_name], alpha=0.8)\n",
        "\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Compositional Generalization')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(models)\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1.1)\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Generalization gap\n",
        "gaps = []\n",
        "for model in models:\n",
        "    train_acc = results.get(model, {}).get('train', 1.0)\n",
        "    extrap_acc = results.get(model, {}).get('test_extrapolation', 0)\n",
        "    if isinstance(train_acc, float) and isinstance(extrap_acc, float):\n",
        "        gap = train_acc - extrap_acc\n",
        "    else:\n",
        "        gap = 0\n",
        "    gaps.append(gap)\n",
        "\n",
        "colors_gap = ['#27ae60' if g < 0.1 else '#e74c3c' for g in gaps]\n",
        "axes[1].bar(models, gaps, color=colors_gap, alpha=0.8)\n",
        "axes[1].set_ylabel('Generalization Gap (Train - Extrapolation)')\n",
        "axes[1].set_title('Generalization Gap\\n(Lower is Better)')\n",
        "axes[1].axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='Good threshold')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('compositional_generalization_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nChart saved as 'compositional_generalization_results.png'\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Analysis & Conclusions"
      ],
      "metadata": {
        "id": "analysis_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed error analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ERROR ANALYSIS: Transformer on Extrapolation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "errors = []\n",
        "for cmd, expected in splits['test_extrapolation']:\n",
        "    predicted = predict_transformer(transformer, cmd, src_vocab, tgt_vocab)\n",
        "    if predicted != expected:\n",
        "        errors.append((cmd, expected, predicted))\n",
        "\n",
        "if errors:\n",
        "    print(f\"\\nTransformer made {len(errors)} errors:\")\n",
        "    for cmd, expected, predicted in errors:\n",
        "        print(f\"  '{cmd}'\")\n",
        "        print(f\"    Expected:  '{expected}'\")\n",
        "        print(f\"    Predicted: '{predicted}'\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No errors on extrapolation set!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"WHY HDC WORKS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "HDC achieves perfect generalization because composition is STRUCTURAL:\n",
        "\n",
        "1. Each primitive has a random hypervector: WALK, RUN, LOOK, etc.\n",
        "2. Each modifier has a random hypervector: TWICE, THRICE, etc.\n",
        "3. Composition uses algebraic operations: bind(LOOK, TWICE)\n",
        "\n",
        "The key insight: bind(LOOK, TWICE) has the same STRUCTURE as bind(WALK, TWICE).\n",
        "The system doesn't need to \"see\" LOOK+TWICE together — the structure guarantees\n",
        "the correct result.\n",
        "\n",
        "This is analogous to how humans understand \"look twice\" without ever hearing it:\n",
        "we understand the RULE, not just the examples.\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"IMPLICATIONS FOR RESONANCE PROJECT\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "This experiment supports the core thesis of rAI:\n",
        "\n",
        "1. MEANING vs STATISTICS\n",
        "   - Transformers learn \"what appears together\" (statistics)\n",
        "   - HDC encodes \"how things relate\" (structure → meaning)\n",
        "\n",
        "2. GENERALIZATION\n",
        "   - Statistical models need exponentially many examples for coverage\n",
        "   - Structural models generalize compositionally from few examples\n",
        "\n",
        "3. EFFICIENCY\n",
        "   - HDC: One-shot learning (store vectors)\n",
        "   - Transformers: Gradient descent over many epochs\n",
        "\n",
        "4. INTERPRETABILITY\n",
        "   - HDC: Structure is explicit and queryable\n",
        "   - Transformers: Black box\n",
        "\n",
        "For Resonance Protocol:\n",
        "- Semantic events should carry STRUCTURAL information, not just embeddings\n",
        "- HDC can be the representation layer for compositional semantics\n",
        "- This enables true generalization on edge devices with minimal data\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Scale up the task** — More complex compositional structures\n",
        "2. **Real-world data** — Test on natural language instructions\n",
        "3. **Hybrid approach** — Combine LLM understanding with HDC structure\n",
        "4. **Edge deployment** — Test on Raspberry Pi / Jetson\n",
        "\n",
        "---\n",
        "\n",
        "*Resonance Protocol Research*\n",
        "- GitHub: https://github.com/nick-yudin/resonance-protocol\n",
        "- Website: https://resonanceprotocol.org"
      ],
      "metadata": {
        "id": "next_steps"
      }
    }
  ]
}
